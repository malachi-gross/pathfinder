{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d9354f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Imports & Setup\n",
    "import re\n",
    "import json\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin, urlparse\n",
    "from tqdm import tqdm\n",
    "import google.generativeai as genai\n",
    "import time\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import psycopg2\n",
    "from psycopg2.extras import RealDictCursor, Json\n",
    "import logging\n",
    "from typing import Dict, List, Optional\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cc02dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Configure API & Database\n",
    "load_dotenv()\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "DATABASE_URL   = os.getenv(\"DATABASE_URL\")\n",
    "\n",
    "if not GEMINI_API_KEY:\n",
    "    raise ValueError(\"GEMINI_API_KEY not found in .env file\")\n",
    "if not DATABASE_URL:\n",
    "    raise ValueError(\"DATABASE_URL not found in .env file\")\n",
    "\n",
    "genai.configure(api_key=GEMINI_API_KEY)\n",
    "\n",
    "BASE_URL     = \"https://catalog.unc.edu\"\n",
    "PROGRAMS_URL = f\"{BASE_URL}/undergraduate/programs-study/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d957173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: ProgramDatabaseManager Class\n",
    "class ProgramDatabaseManager:\n",
    "    def __init__(self, db_url: str):\n",
    "        # Parse the URL\n",
    "        url = urlparse(db_url)\n",
    "        \n",
    "        conn_params = {\n",
    "            \"host\": url.hostname,\n",
    "            \"port\": url.port,\n",
    "            \"database\": url.path[1:],\n",
    "            \"user\": url.username,\n",
    "            \"password\": url.password,\n",
    "            \"sslmode\": \"require\",\n",
    "            \"gssencmode\": \"disable\"\n",
    "        }\n",
    "        \n",
    "        self.conn = psycopg2.connect(**conn_params)\n",
    "        self.conn.autocommit = False\n",
    "        self.cur = self.conn.cursor(cursor_factory=RealDictCursor)\n",
    "        self.course_id_cache = {}\n",
    "        self._load_course_cache()\n",
    "    \n",
    "    def _load_course_cache(self):\n",
    "        self.cur.execute(\"SELECT id, course_id FROM courses\")\n",
    "        for row in self.cur.fetchall():\n",
    "            self.course_id_cache[row['course_id']] = row['id']\n",
    "        logger.info(f\"Loaded {len(self.course_id_cache)} courses into cache\")\n",
    "    \n",
    "    def save_program(self, program_data: Dict) -> Optional[int]:\n",
    "        try:\n",
    "            self.cur.execute(\"\"\"\n",
    "                INSERT INTO programs \n",
    "                  (program_id, name, program_type, degree_type, total_hours, url)\n",
    "                VALUES (%s,%s,%s,%s,%s,%s)\n",
    "                ON CONFLICT (program_id) DO UPDATE SET\n",
    "                  name=EXCLUDED.name,\n",
    "                  program_type=EXCLUDED.program_type,\n",
    "                  degree_type=EXCLUDED.degree_type,\n",
    "                  total_hours=EXCLUDED.total_hours,\n",
    "                  url=EXCLUDED.url,\n",
    "                  updated_at=NOW()\n",
    "                RETURNING id\n",
    "            \"\"\", (\n",
    "                program_data.get('program_id'),\n",
    "                program_data.get('program_name'),\n",
    "                program_data.get('program_type', 'major'),\n",
    "                program_data.get('degree_type'),\n",
    "                program_data.get('total_hours'),\n",
    "                program_data.get('url')\n",
    "            ))\n",
    "            prog_id = self.cur.fetchone()['id']\n",
    "            if program_data.get('requirements'):\n",
    "                self._save_program_requirements(prog_id, program_data['requirements'])\n",
    "            return prog_id\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error saving program {program_data.get('program_name')}: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def _save_program_requirements(self, program_db_id: int, requirements: Dict):\n",
    "        self.cur.execute(\"\"\"\n",
    "            DELETE FROM program_requirement_courses \n",
    "            WHERE requirement_id IN (\n",
    "              SELECT id FROM program_requirements WHERE program_id=%s\n",
    "            )\n",
    "        \"\"\", (program_db_id,))\n",
    "        self.cur.execute(\"DELETE FROM program_requirements WHERE program_id=%s\", (program_db_id,))\n",
    "        \n",
    "        display_order = 0\n",
    "        mappings = [\n",
    "            ('gateway_courses', 'gateway'),\n",
    "            ('core_requirements','core'),\n",
    "            ('electives','elective'),\n",
    "            ('allied_sciences','allied_science')\n",
    "        ]\n",
    "        for json_key, req_type in mappings:\n",
    "            items = requirements.get(json_key, [])\n",
    "            for item in items:\n",
    "                category    = item.get('category', json_key)\n",
    "                min_credits = item.get('min_credits', item.get('total_credits'))\n",
    "                min_courses = item.get('min_courses')\n",
    "                select_note = item.get('selection_notes') or item.get('notes')\n",
    "                level_req   = item.get('level_requirement')\n",
    "                other_rest  = item.get('restrictions') or item.get('other_restrictions')\n",
    "                \n",
    "                self.cur.execute(\"\"\"\n",
    "                    INSERT INTO program_requirements\n",
    "                      (program_id, requirement_type, category_name, min_credits,\n",
    "                       min_courses, selection_notes, level_requirement,\n",
    "                       other_restrictions, display_order)\n",
    "                    VALUES (%s,%s,%s,%s,%s,%s,%s,%s,%s)\n",
    "                    RETURNING id\n",
    "                \"\"\", (\n",
    "                    program_db_id, req_type, category, min_credits,\n",
    "                    min_courses, select_note, level_req,\n",
    "                    other_rest, display_order\n",
    "                ))\n",
    "                req_id = self.cur.fetchone()['id']\n",
    "                display_order += 1\n",
    "                self._save_requirement_courses(req_id, item)\n",
    "    \n",
    "    def _save_requirement_courses(self, req_id: int, item: Dict):\n",
    "        courses = []\n",
    "        if isinstance(item.get('courses'), list):\n",
    "            for c in item['courses']:\n",
    "                if isinstance(c, dict):\n",
    "                    courses.append((c.get('course_code') or c.get('course'), True))\n",
    "                else:\n",
    "                    courses.append((c, True))\n",
    "        elif item.get('course_code'):\n",
    "            courses.append((item['course_code'], True))\n",
    "        for code, required in courses:\n",
    "            cid = self.course_id_cache.get(code)\n",
    "            if cid:\n",
    "                try:\n",
    "                    self.cur.execute(\"\"\"\n",
    "                        INSERT INTO program_requirement_courses\n",
    "                          (requirement_id, course_id, is_required)\n",
    "                        VALUES (%s,%s,%s)\n",
    "                        ON CONFLICT (requirement_id, course_id) DO NOTHING\n",
    "                    \"\"\", (req_id, cid, required))\n",
    "                except Exception as e:\n",
    "                    logger.warning(f\"Failed linking {code}: {e}\")\n",
    "    \n",
    "    def commit(self):   self.conn.commit()\n",
    "    def rollback(self): self.conn.rollback()\n",
    "    def close(self):    self.cur.close(); self.conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1f58b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: RequirementsParser Class\n",
    "class RequirementsParser:\n",
    "    def __init__(self, model=\"gemini-1.5-flash\", delay: float = 2.1):\n",
    "        self.model = genai.GenerativeModel(model)\n",
    "        self.delay = delay\n",
    "        self.api_calls = 0\n",
    "        self.failed_parses = []\n",
    "        self.last_call_time = 0\n",
    "\n",
    "    def parse_requirements(self, html_content: str, program_name: str = None) -> dict:\n",
    "        soup = BeautifulSoup(html_content, 'html.parser')\n",
    "        req_div = soup.find('div', {'id':'requirementstextcontainer'}) or soup.find('div',{'id':'right-col'})\n",
    "        if not req_div:\n",
    "            return {\"error\":\"No requirements content found\",\"requirements\":{}}\n",
    "        html = str(req_div)\n",
    "        now = time.time(); elapsed = now - self.last_call_time\n",
    "        if elapsed < self.delay: time.sleep(self.delay - elapsed)\n",
    "        self.last_call_time = time.time(); self.api_calls += 1\n",
    "\n",
    "        prompt = f\"\"\"Parse the following HTML into JSON (program_type,degree_type,total_hours,requirements,footnotes,special_notes):\n",
    "\n",
    "{html}\n",
    "\n",
    "Return ONLY JSON.\"\"\"\n",
    "        try:\n",
    "            resp = self.model.generate_content(prompt)\n",
    "            txt  = resp.text.strip()\n",
    "            txt  = re.sub(r'^```json\\s*','',txt)\n",
    "            txt  = re.sub(r'\\s*```$','',txt)\n",
    "            return json.loads(txt)\n",
    "        except Exception as e:\n",
    "            if program_name: self.failed_parses.append((program_name,str(e)))\n",
    "            return {\"error\":f\"Failed to parse: {e}\",\"requirements\":{},\"program_name\":program_name}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e7a016d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Scraping Functions\n",
    "def get_program_links():\n",
    "    resp = requests.get(PROGRAMS_URL)\n",
    "    soup = BeautifulSoup(resp.text, 'html.parser')\n",
    "    sitemap = soup.find('div', {'class':'az_sitemap'})\n",
    "    if not sitemap: return []\n",
    "    links=[]\n",
    "    for a in sitemap.find_all('a',href=True):\n",
    "        href, name = a['href'], a.text.strip()\n",
    "        if 'programs-study' not in href: continue\n",
    "        url = urljoin(BASE_URL, href)\n",
    "        if '#' not in url: url += '#requirementstext'\n",
    "        links.append({'name':name,'url':url,'program_id':href.split('/')[-2]})\n",
    "    return links\n",
    "\n",
    "def scrape_program(url: str, parser: RequirementsParser, info: dict,\n",
    "                   db_mgr: Optional[ProgramDatabaseManager]=None, mode: str='database'):\n",
    "    try:\n",
    "        resp = requests.get(url); resp.raise_for_status()\n",
    "        result = parser.parse_requirements(resp.text, info['name'])\n",
    "        result.update({'program_name':info['name'],'program_id':info['program_id'],'url':url})\n",
    "        if mode in ['database','both'] and db_mgr and 'error' not in result:\n",
    "            try: db_mgr.save_program(result)\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Save error {info['name']}: {e}\")\n",
    "                result['database_error']=str(e)\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error scraping {info['name']}: {e}\")\n",
    "        return {'program_name':info['name'],'program_id':info['program_id'],'url':url,'error':str(e)}\n",
    "\n",
    "def scrape_all_programs(parser: RequirementsParser, db_mgr: Optional[ProgramDatabaseManager]=None,\n",
    "                       limit: Optional[int]=None, mode: str='database', dry_run: bool=False):\n",
    "    print(\"🔍 Finding all program links...\")\n",
    "    prog_links = get_program_links()\n",
    "    if limit: prog_links = prog_links[:limit]\n",
    "    print(f\"🎯 Found {len(prog_links)} programs to scrape — mode={mode}, dry_run={dry_run}\\n\")\n",
    "    all_progs=[]; saved=0; start_all=time.time()\n",
    "    for idx, info in enumerate(prog_links,1):\n",
    "        print(f\"📚 [{idx}/{len(prog_links)}] Scraping {info['name']}...\")\n",
    "        if db_mgr and not dry_run: db_mgr.conn.commit()\n",
    "        start=time.time()\n",
    "        res=scrape_program(info['url'],parser,info,db_mgr if not dry_run else None,mode)\n",
    "        if mode in ['json','both']: all_progs.append(res)\n",
    "        if db_mgr and not dry_run and mode in ['database','both'] and 'error' not in res:\n",
    "            try: db_mgr.commit(); saved+=1\n",
    "            except: db_mgr.rollback()\n",
    "        print(f\"{'✅' if 'error' not in res else '⚠️'} Completed in {time.time()-start:.1f}s\\n\")\n",
    "    print(f\"⏱️ Total time: {(time.time()-start_all)/60:.1f}m — saved {saved} programs\")\n",
    "    return all_progs\n",
    "\n",
    "def save_to_json(data, filename=\"unc_programs.json\"):\n",
    "    with open(filename,\"w\",encoding=\"utf-8\") as f:\n",
    "        json.dump(data,f,indent=2,ensure_ascii=False)\n",
    "    print(f\"💾 Saved to {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83d91161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Analysis Utilities\n",
    "def analyze_programs(programs):\n",
    "    total = len(programs)\n",
    "    success = len([p for p in programs if 'error' not in p])\n",
    "    failed  = total - success\n",
    "    print(f\"\\n📊 Summary: total={total}, success={success}, failed={failed}\")\n",
    "    if failed:\n",
    "        print(\"\\n⚠️ Failed programs:\")\n",
    "        for p in programs:\n",
    "            if 'error' in p:\n",
    "                print(f\" - {p['program_name']}: {p['error'][:50]}...\")\n",
    "\n",
    "def find_program(programs, term):\n",
    "    term = term.lower()\n",
    "    matches=[p for p in programs if term in p['program_name'].lower()]\n",
    "    print(f\"\\n🔍 Found {len(matches)} programs matching '{term}':\")\n",
    "    for p in matches:\n",
    "        print(f\" • {p['program_name']} ({p['program_type']})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9b12fa89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-20 23:32:25,304 - INFO - Loaded 123 courses into cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧪 Testing with first 5 programs...\n",
      "\n",
      "🔍 Finding all program links...\n",
      "🎯 Found 5 programs to scrape — mode=database, dry_run=False\n",
      "\n",
      "📚 [1/5] Scraping Aerospace Studies Minor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-20 23:32:27,356 - ERROR - Error saving program Aerospace Studies Minor: null value in column \"program_type\" of relation \"programs\" violates not-null constraint\n",
      "DETAIL:  Failing row contains (1, aerospace-studies-minor, Aerospace Studies Minor, null, null, 14, https://catalog.unc.edu/undergraduate/programs-study/aerospace-s..., 2025-07-21 04:32:27.274573, 2025-07-21 04:32:27.274573).\n",
      "\n",
      "2025-07-20 23:32:27,357 - ERROR - Save error Aerospace Studies Minor: null value in column \"program_type\" of relation \"programs\" violates not-null constraint\n",
      "DETAIL:  Failing row contains (1, aerospace-studies-minor, Aerospace Studies Minor, null, null, 14, https://catalog.unc.edu/undergraduate/programs-study/aerospace-s..., 2025-07-21 04:32:27.274573, 2025-07-21 04:32:27.274573).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed in 1.8s\n",
      "\n",
      "📚 [2/5] Scraping African American and Diaspora Studies Minor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-20 23:32:34,012 - ERROR - Error saving program African American and Diaspora Studies Minor: 'list' object has no attribute 'get'\n",
      "2025-07-20 23:32:34,013 - ERROR - Save error African American and Diaspora Studies Minor: 'list' object has no attribute 'get'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed in 6.7s\n",
      "\n",
      "📚 [3/5] Scraping African Studies Minor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-20 23:32:38,146 - ERROR - Error saving program African Studies Minor: value too long for type character varying(10)\n",
      "\n",
      "2025-07-20 23:32:38,146 - ERROR - Save error African Studies Minor: value too long for type character varying(10)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed in 4.1s\n",
      "\n",
      "📚 [4/5] Scraping African, African American, and Diaspora Studies Major, B.A....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-20 23:32:40,286 - ERROR - Error saving program African, African American, and Diaspora Studies Major, B.A.: null value in column \"program_type\" of relation \"programs\" violates not-null constraint\n",
      "DETAIL:  Failing row contains (3, african-african-american-diaspora-studies-major-ba, African, African American, and Diaspora Studies Major, B.A., null, null, 27, https://catalog.unc.edu/undergraduate/programs-study/african-afr..., 2025-07-21 04:32:40.241133, 2025-07-21 04:32:40.241133).\n",
      "\n",
      "2025-07-20 23:32:40,286 - ERROR - Save error African, African American, and Diaspora Studies Major, B.A.: null value in column \"program_type\" of relation \"programs\" violates not-null constraint\n",
      "DETAIL:  Failing row contains (3, african-african-american-diaspora-studies-major-ba, African, African American, and Diaspora Studies Major, B.A., null, null, 27, https://catalog.unc.edu/undergraduate/programs-study/african-afr..., 2025-07-21 04:32:40.241133, 2025-07-21 04:32:40.241133).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed in 2.1s\n",
      "\n",
      "📚 [5/5] Scraping American Indian and Indigenous Studies Minor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-20 23:32:42,676 - ERROR - Error saving program American Indian and Indigenous Studies Minor: value too long for type character varying(10)\n",
      "\n",
      "2025-07-20 23:32:42,677 - ERROR - Save error American Indian and Indigenous Studies Minor: value too long for type character varying(10)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed in 2.4s\n",
      "\n",
      "⏱️ Total time: 0.3m — saved 5 programs\n",
      "\n",
      "📊 API calls: 5, Failed parses: 0\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Main Execution\n",
    "parser     = RequirementsParser(model=\"gemini-1.5-flash\", delay=2.1)\n",
    "db_manager = ProgramDatabaseManager(DATABASE_URL)\n",
    "\n",
    "MODE   = 'database'   # 'database','json', or 'both'\n",
    "DRY    = False\n",
    "LIMIT  = 5            # None for all programs\n",
    "\n",
    "print(\"🧪 Testing with first 5 programs...\\n\")\n",
    "programs = scrape_all_programs(parser, db_manager, limit=LIMIT, mode=MODE, dry_run=DRY)\n",
    "if MODE in ['json','both']:\n",
    "    save_to_json(programs, \"unc_programs_test.json\")\n",
    "    analyze_programs(programs)\n",
    "\n",
    "print(f\"\\n📊 API calls: {parser.api_calls}, Failed parses: {len(parser.failed_parses)}\")\n",
    "db_manager.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e8176ec6",
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "could not translate host name \"db.xqovabeviuvdtqjeaomo.supabase.co\" to address: Name or service not known\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOperationalError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     11\u001b[39m             reqs = db.get_program_requirements(prog[\u001b[33m'\u001b[39m\u001b[33mprogram_id\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m     12\u001b[39m             \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m   Categories: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(reqs)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m; sample: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreqs[\u001b[32m0\u001b[39m][\u001b[33m'\u001b[39m\u001b[33mcategory_name\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mif\u001b[39;00m\u001b[38;5;250m \u001b[39mreqs\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01melse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[33m'\u001b[39m\u001b[33mN/A\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m \u001b[43mverify_program_scraping\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 4\u001b[39m, in \u001b[36mverify_program_scraping\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mverify_program_scraping\u001b[39m():\n\u001b[32m      3\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdb_queries\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CourseDatabase\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mCourseDatabase\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m db:\n\u001b[32m      5\u001b[39m         stats = db.get_database_stats()\n\u001b[32m      6\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m🔍 Program Stats: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstats\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\malac\\pathfinder\\scraping\\db_queries.py:14\u001b[39m, in \u001b[36mCourseDatabase.__init__\u001b[39m\u001b[34m(self, db_url)\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Initialize database connection.\"\"\"\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;28mself\u001b[39m.db_url = db_url \u001b[38;5;129;01mor\u001b[39;00m os.getenv(\u001b[33m'\u001b[39m\u001b[33mDATABASE_URL\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m \u001b[38;5;28mself\u001b[39m.conn = \u001b[43mpsycopg2\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdb_url\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[38;5;28mself\u001b[39m.cur = \u001b[38;5;28mself\u001b[39m.conn.cursor(cursor_factory=RealDictCursor)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\malac\\anaconda3\\envs\\pathfinder\\Lib\\site-packages\\psycopg2\\__init__.py:122\u001b[39m, in \u001b[36mconnect\u001b[39m\u001b[34m(dsn, connection_factory, cursor_factory, **kwargs)\u001b[39m\n\u001b[32m    119\u001b[39m     kwasync[\u001b[33m'\u001b[39m\u001b[33masync_\u001b[39m\u001b[33m'\u001b[39m] = kwargs.pop(\u001b[33m'\u001b[39m\u001b[33masync_\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    121\u001b[39m dsn = _ext.make_dsn(dsn, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m conn = \u001b[43m_connect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdsn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconnection_factory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconnection_factory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwasync\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cursor_factory \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    124\u001b[39m     conn.cursor_factory = cursor_factory\n",
      "\u001b[31mOperationalError\u001b[39m: could not translate host name \"db.xqovabeviuvdtqjeaomo.supabase.co\" to address: Name or service not known\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Verification / Lookup\n",
    "def verify_program_scraping():\n",
    "    from db_queries import CourseDatabase\n",
    "    with CourseDatabase() as db:\n",
    "        stats = db.get_database_stats()\n",
    "        print(f\"\\n🔍 Program Stats: {stats}\")\n",
    "        compsci = db.search_programs(\"computer science\")\n",
    "        print(f\"\\n📚 Found {len(compsci)} CS programs:\")\n",
    "        for prog in compsci:\n",
    "            print(f\" - {prog['name']} ({prog['program_type']})\")\n",
    "            reqs = db.get_program_requirements(prog['program_id'])\n",
    "            print(f\"   Categories: {len(reqs)}; sample: {reqs[0]['category_name'] if reqs else 'N/A'}\")\n",
    "\n",
    "verify_program_scraping()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pathfinder",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
