{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c3a9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Import and setup\n",
    "import re\n",
    "import json\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "from tqdm import tqdm\n",
    "import google.generativeai as genai\n",
    "import time\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import psycopg2\n",
    "from psycopg2.extras import RealDictCursor\n",
    "import logging\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Optional\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344947c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Configure API and Database\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "DATABASE_URL = os.getenv(\"DATABASE_URL\")\n",
    "\n",
    "if not GEMINI_API_KEY:\n",
    "    raise ValueError(\"GEMINI_API_KEY not found in .env file\")\n",
    "\n",
    "if not DATABASE_URL:\n",
    "    raise ValueError(\"DATABASE_URL not found in .env file\")\n",
    "\n",
    "genai.configure(api_key=GEMINI_API_KEY)\n",
    "\n",
    "BASE_URL = \"https://catalog.unc.edu\"\n",
    "COURSE_INDEX_URL = f\"{BASE_URL}/courses/#text\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c1151b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Database Manager class\n",
    "class DatabaseManager:\n",
    "    def __init__(self, db_url: str):\n",
    "        \"\"\"Initialize database connection and caches.\"\"\"\n",
    "        # Parse the URL\n",
    "        from urllib.parse import urlparse\n",
    "        url = urlparse(db_url)\n",
    "        \n",
    "        conn_params = {\n",
    "            \"host\": url.hostname,\n",
    "            \"port\": url.port,\n",
    "            \"database\": url.path[1:],\n",
    "            \"user\": url.username,\n",
    "            \"password\": url.password,\n",
    "            \"sslmode\": \"require\",\n",
    "            \"gssencmode\": \"disable\"\n",
    "        }\n",
    "        \n",
    "        self.conn = psycopg2.connect(**conn_params)\n",
    "        self.conn.autocommit = False\n",
    "        self.cur = self.conn.cursor(cursor_factory=RealDictCursor)\n",
    "        \n",
    "        # Cache for lookups\n",
    "        self.department_cache = {}\n",
    "        self.course_id_cache = {}\n",
    "        \n",
    "        # Load existing data into cache\n",
    "        self._load_cache()\n",
    "    \n",
    "    def _load_cache(self):\n",
    "        \"\"\"Load existing departments and courses into cache.\"\"\"\n",
    "        # Load departments\n",
    "        self.cur.execute(\"SELECT id, code FROM departments\")\n",
    "        for row in self.cur.fetchall():\n",
    "            self.department_cache[row['code']] = row['id']\n",
    "        \n",
    "        # Load course IDs\n",
    "        self.cur.execute(\"SELECT id, course_id FROM courses\")\n",
    "        for row in self.cur.fetchall():\n",
    "            self.course_id_cache[row['course_id']] = row['id']\n",
    "        \n",
    "        logger.info(f\"Loaded {len(self.department_cache)} departments and {len(self.course_id_cache)} courses into cache\")\n",
    "    \n",
    "    def get_or_create_department(self, dept_code: str) -> int:\n",
    "        \"\"\"Get or create a department, returning its ID.\"\"\"\n",
    "        if dept_code in self.department_cache:\n",
    "            return self.department_cache[dept_code]\n",
    "        \n",
    "        self.cur.execute(\"\"\"\n",
    "            INSERT INTO departments (code) \n",
    "            VALUES (%s) \n",
    "            ON CONFLICT (code) DO UPDATE SET code = EXCLUDED.code\n",
    "            RETURNING id\n",
    "        \"\"\", (dept_code,))\n",
    "        \n",
    "        dept_id = self.cur.fetchone()['id']\n",
    "        self.department_cache[dept_code] = dept_id\n",
    "        return dept_id\n",
    "    \n",
    "    def save_course(self, course_data: Dict) -> Optional[int]:\n",
    "        \"\"\"Save a course to the database.\"\"\"\n",
    "        try:\n",
    "            dept_id = self.get_or_create_department(course_data['department'])\n",
    "            \n",
    "            # Extract repeat rules if present\n",
    "            repeatable = False\n",
    "            max_repeat_credits = None\n",
    "            max_repeat_completions = None\n",
    "            \n",
    "            if course_data.get('repeat_rules'):\n",
    "                repeat_rules = course_data['repeat_rules']\n",
    "                repeatable = repeat_rules.get('repeatable', False)\n",
    "                max_repeat_credits = repeat_rules.get('max_credits')\n",
    "                max_repeat_completions = repeat_rules.get('max_completions')\n",
    "            \n",
    "            # Insert or update course\n",
    "            self.cur.execute(\"\"\"\n",
    "                INSERT INTO courses \n",
    "                (course_id, department_id, course_number, name, description, \n",
    "                 credits, grading_status, requisites_note, repeatable, \n",
    "                 max_repeat_credits, max_repeat_completions)\n",
    "                VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "                ON CONFLICT (course_id) DO UPDATE SET\n",
    "                    name = EXCLUDED.name,\n",
    "                    description = EXCLUDED.description,\n",
    "                    credits = EXCLUDED.credits,\n",
    "                    grading_status = EXCLUDED.grading_status,\n",
    "                    requisites_note = EXCLUDED.requisites_note,\n",
    "                    repeatable = EXCLUDED.repeatable,\n",
    "                    max_repeat_credits = EXCLUDED.max_repeat_credits,\n",
    "                    max_repeat_completions = EXCLUDED.max_repeat_completions,\n",
    "                    updated_at = NOW()\n",
    "                RETURNING id\n",
    "            \"\"\", (\n",
    "                course_data['course_id'],\n",
    "                dept_id,\n",
    "                course_data['course_number'],\n",
    "                course_data['course_name'],\n",
    "                course_data.get('description'),\n",
    "                course_data.get('credits'),\n",
    "                course_data.get('grading_status'),\n",
    "                course_data.get('requisites_note'),\n",
    "                repeatable,\n",
    "                max_repeat_credits,\n",
    "                max_repeat_completions\n",
    "            ))\n",
    "            \n",
    "            course_db_id = self.cur.fetchone()['id']\n",
    "            self.course_id_cache[course_data['course_id']] = course_db_id\n",
    "            \n",
    "            # Save prerequisites if present\n",
    "            if course_data.get('requisites'):\n",
    "                self._save_prerequisites(course_db_id, course_data['requisites'])\n",
    "            \n",
    "            # Save grade requirements if present\n",
    "            if course_data.get('grade_requirements'):\n",
    "                self._save_grade_requirements(course_db_id, course_data['grade_requirements'])\n",
    "            \n",
    "            # Save gen ed fulfillments to normalized table\n",
    "            if course_data.get('gen_ed'):\n",
    "                self._save_gen_ed_fulfillments(course_db_id, course_data['gen_ed'])\n",
    "            \n",
    "            return course_db_id\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error saving course {course_data.get('course_id')}: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def _save_gen_ed_fulfillments(self, course_db_id: int, gen_ed_groups: List[List[str]]):\n",
    "        \"\"\"Save gen ed fulfillments to normalized table.\"\"\"\n",
    "        # Clear existing fulfillments\n",
    "        self.cur.execute(\"DELETE FROM gen_ed_fulfillments WHERE course_id = %s\", (course_db_id,))\n",
    "        \n",
    "        # Save new fulfillments\n",
    "        for group_idx, group in enumerate(gen_ed_groups):\n",
    "            for gen_ed_code in group:\n",
    "                if gen_ed_code:  # Skip empty codes\n",
    "                    self.cur.execute(\"\"\"\n",
    "                        INSERT INTO gen_ed_fulfillments (course_id, gen_ed_code, requirement_group)\n",
    "                        VALUES (%s, %s, %s)\n",
    "                        ON CONFLICT (course_id, gen_ed_code) DO NOTHING\n",
    "                    \"\"\", (course_db_id, gen_ed_code.strip(), group_idx))\n",
    "    \n",
    "    def _save_prerequisites(self, course_db_id: int, requisites: Dict):\n",
    "        \"\"\"Save prerequisites for a course.\"\"\"\n",
    "        # Clear existing prerequisites\n",
    "        self.cur.execute(\"DELETE FROM prerequisites WHERE course_id = %s\", (course_db_id,))\n",
    "        \n",
    "        # Save prerequisites (AND groups)\n",
    "        for group_idx, prereq_group in enumerate(requisites.get('prerequisites', [])):\n",
    "            for prereq_course_code in prereq_group:\n",
    "                prereq_db_id = self.course_id_cache.get(prereq_course_code.strip())\n",
    "                if prereq_db_id:\n",
    "                    self.cur.execute(\"\"\"\n",
    "                        INSERT INTO prerequisites \n",
    "                        (course_id, prereq_group, prereq_course_id, is_corequisite)\n",
    "                        VALUES (%s, %s, %s, %s)\n",
    "                        ON CONFLICT DO NOTHING\n",
    "                    \"\"\", (course_db_id, group_idx, prereq_db_id, False))\n",
    "        \n",
    "        # Save corequisites\n",
    "        for group_idx, coreq_group in enumerate(requisites.get('corequisites', [])):\n",
    "            for coreq_course_code in coreq_group:\n",
    "                coreq_db_id = self.course_id_cache.get(coreq_course_code.strip())\n",
    "                if coreq_db_id:\n",
    "                    self.cur.execute(\"\"\"\n",
    "                        INSERT INTO prerequisites \n",
    "                        (course_id, prereq_group, prereq_course_id, is_corequisite)\n",
    "                        VALUES (%s, %s, %s, %s)\n",
    "                        ON CONFLICT DO NOTHING\n",
    "                    \"\"\", (course_db_id, group_idx + 1000, coreq_db_id, True))\n",
    "    \n",
    "    def _save_grade_requirements(self, course_db_id: int, grade_requirements: Dict):\n",
    "        \"\"\"Save grade requirements for a course.\"\"\"\n",
    "        # Clear existing grade requirements\n",
    "        self.cur.execute(\"DELETE FROM grade_requirements WHERE course_id = %s\", (course_db_id,))\n",
    "        \n",
    "        for req_course_code, min_grade in grade_requirements.items():\n",
    "            # Try different formats\n",
    "            req_course_code = req_course_code.replace(' ', '')\n",
    "            req_db_id = None\n",
    "            for possible_code in [req_course_code, f\"{req_course_code[:4]} {req_course_code[4:]}\"]:\n",
    "                req_db_id = self.course_id_cache.get(possible_code)\n",
    "                if req_db_id:\n",
    "                    break\n",
    "            \n",
    "            if req_db_id:\n",
    "                self.cur.execute(\"\"\"\n",
    "                    INSERT INTO grade_requirements \n",
    "                    (course_id, required_course_id, minimum_grade)\n",
    "                    VALUES (%s, %s, %s)\n",
    "                    ON CONFLICT DO NOTHING\n",
    "                \"\"\", (course_db_id, req_db_id, min_grade))\n",
    "    \n",
    "    def commit(self):\n",
    "        \"\"\"Commit the current transaction.\"\"\"\n",
    "        self.conn.commit()\n",
    "    \n",
    "    def rollback(self):\n",
    "        \"\"\"Rollback the current transaction.\"\"\"\n",
    "        self.conn.rollback()\n",
    "    \n",
    "    def close(self):\n",
    "        \"\"\"Close database connection.\"\"\"\n",
    "        self.cur.close()\n",
    "        self.conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac923bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: RequisiteParser class (same as before with minor modifications)\n",
    "class RequisiteParser:\n",
    "    def __init__(self, model=\"gemini-2.5-flash\", delay: float = 0.5):\n",
    "        \"\"\"Initialize the parser with Gemini API.\"\"\"\n",
    "        self.model = genai.GenerativeModel(model)\n",
    "        self.delay = delay\n",
    "        self.api_calls = 0\n",
    "        self.failed_parses = []\n",
    "        self.last_call_time = 0\n",
    "        \n",
    "    def parse_requisites(self, raw: str, course_id: str = None) -> dict:\n",
    "        \"\"\"Parse requisites using Gemini API.\"\"\"\n",
    "        if not raw or not raw.strip():\n",
    "            return {\n",
    "                \"prerequisites\": [],\n",
    "                \"corequisites\": [],\n",
    "                \"grade_requirements\": {},\n",
    "                \"requisites_note\": None\n",
    "            }\n",
    "        \n",
    "        # Rate limiting\n",
    "        current_time = time.time()\n",
    "        time_since_last_call = current_time - self.last_call_time\n",
    "        if time_since_last_call < self.delay:\n",
    "            sleep_time = self.delay - time_since_last_call\n",
    "            time.sleep(sleep_time)\n",
    "        \n",
    "        self.last_call_time = time.time()\n",
    "        self.api_calls += 1\n",
    "        \n",
    "        prompt = f\"\"\"Parse the following course requisite statement and return a JSON object with this exact structure:\n",
    "\n",
    "{{\n",
    "    \"prerequisites\": [\n",
    "        // List of AND-groups, where each group is a list of courses that can be taken as alternatives (OR)\n",
    "        // Example: [[\"COMP 110\"], [\"MATH 231\", \"MATH 241\"]] means COMP 110 AND (MATH 231 OR MATH 241)\n",
    "    ],\n",
    "    \"corequisites\": [\n",
    "        // Same structure as prerequisites but for co-requisites\n",
    "    ],\n",
    "    \"grade_requirements\": {{\n",
    "        // Map of course to required grade\n",
    "        // Example: {{\"COMP 110\": \"C\", \"MATH 231\": \"C+\"}}\n",
    "    }},\n",
    "    \"requisites_note\": // String with any additional requirements like \"permission of instructor\" or null if none\n",
    "}}\n",
    "\n",
    "CRITICAL PARSING RULES:\n",
    "\n",
    "1. AND relationships (all required):\n",
    "   - Separated by \"and\", semicolons (;), or commas in a list\n",
    "   - Example: \"COMP 110 and MATH 231\" â†’ [[\"COMP 110\"], [\"MATH 231\"]]\n",
    "   - Example: \"COMP 210; COMP 211; COMP 301\" â†’ [[\"COMP 210\"], [\"COMP 211\"], [\"COMP 301\"]]\n",
    "\n",
    "2. OR relationships (choose one):\n",
    "   - Separated by \"or\"\n",
    "   - Example: \"COMP 283 or MATH 381 or STOR 315\" â†’ [[\"COMP 283\", \"MATH 381\", \"STOR 315\"]]\n",
    "\n",
    "3. Mixed AND/OR:\n",
    "   - Example: \"MATH 231 or 241; COMP 210, COMP 211, and COMP 301\"\n",
    "   - Parse as: [[\"MATH 231\", \"MATH 241\"], [\"COMP 210\"], [\"COMP 211\"], [\"COMP 301\"]]\n",
    "   - The semicolon separates AND groups, \"or\" creates OR options within a group\n",
    "\n",
    "4. Pre- or corequisites:\n",
    "   - Add the SAME courses to BOTH prerequisites and corequisites arrays\n",
    "   - Example: \"Pre- or corequisites, COMP 283 or MATH 381\"\n",
    "   - Prerequisites: [[\"COMP 283\", \"MATH 381\"]]\n",
    "   - Corequisites: [[\"COMP 283\", \"MATH 381\"]]\n",
    "\n",
    "5. Grade requirements:\n",
    "   - Look for \"grade of X or better\", \"C or better\", etc.\n",
    "   - Apply to ALL courses mentioned in the same clause\n",
    "   - Example: \"COMP 211 and COMP 301; a grade of C or better is required in both\"\n",
    "   - grade_requirements: {{\"COMP 211\": \"C\", \"COMP 301\": \"C\"}}\n",
    "\n",
    "6. Course code format:\n",
    "   - Always format as \"DEPT ###\" with a space (e.g., \"COMP 110\", not \"COMP110\")\n",
    "   - Include letter suffixes if present (e.g., \"BIOL 101L\")\n",
    "\n",
    "7. Special requirements (put in requisites_note):\n",
    "   - \"Permission of the instructor\" â†’ Include exact text\n",
    "   - \"May be repeated for credit\" â†’ Include this note\n",
    "   - \"Not open to students who have credit for X\" â†’ Include full restriction\n",
    "   - \"for students lacking the prerequisite\" â†’ Include context\n",
    "   - Any GPA requirements â†’ Include exact GPA needed\n",
    "   - Class standing restrictions (e.g., \"Juniors and seniors only\")\n",
    "\n",
    "Common patterns to recognize:\n",
    "- \"Prerequisites, X and Y\" â†’ both required\n",
    "- \"Prerequisite, X or Y\" â†’ choose one\n",
    "- \"Prerequisites, X; Y or Z\" â†’ X is required AND (Y OR Z)\n",
    "- \"one of the following\" â†’ all listed courses are OR options\n",
    "- \"all of the following\" â†’ all listed courses are AND requirements\n",
    "- \"permission of the instructor for students lacking the prerequisite\" â†’ courses are still required, but add note about permission option\n",
    "\n",
    "Example complex requisite:\n",
    "\"Prerequisites, COMP 211 and 301, or COMP 401, 410, and 411; a grade of C or better is required in all prerequisite courses; permission of the instructor for students lacking the prerequisites; may be repeated for credit.\"\n",
    "\n",
    "Should parse to:\n",
    "{{\n",
    "    \"prerequisites\": [[\"COMP 211\", \"COMP 301\"], [\"COMP 401\", \"COMP 410\", \"COMP 411\"]],\n",
    "    \"corequisites\": [],\n",
    "    \"grade_requirements\": {{\"COMP 211\": \"C\", \"COMP 301\": \"C\", \"COMP 401\": \"C\", \"COMP 410\": \"C\", \"COMP 411\": \"C\"}},\n",
    "    \"requisites_note\": \"permission of the instructor for students lacking the prerequisites; may be repeated for credit\"\n",
    "}}\n",
    "\n",
    "Requisite statement to parse:\n",
    "{raw}\n",
    "\n",
    "Return ONLY the JSON object, no explanation or markdown.\"\"\"\n",
    "\n",
    "        try:\n",
    "            response = self.model.generate_content(prompt)\n",
    "            json_text = response.text.strip()\n",
    "            json_text = re.sub(r'^```json\\s*', '', json_text)\n",
    "            json_text = re.sub(r'\\s*```$', '', json_text)\n",
    "            \n",
    "            result = json.loads(json_text)\n",
    "            return self._validate_result(result)\n",
    "            \n",
    "        except Exception as e:\n",
    "            if course_id:\n",
    "                self.failed_parses.append((course_id, str(e)))\n",
    "            return self._fallback_parse(raw)\n",
    "    \n",
    "    def _validate_result(self, result: dict) -> dict:\n",
    "        \"\"\"Validate and clean the parsed result.\"\"\"\n",
    "        validated = {\n",
    "            \"prerequisites\": result.get(\"prerequisites\", []),\n",
    "            \"corequisites\": result.get(\"corequisites\", []),\n",
    "            \"grade_requirements\": result.get(\"grade_requirements\", {}),\n",
    "            \"requisites_note\": result.get(\"requisites_note\", None)\n",
    "        }\n",
    "        \n",
    "        # Ensure prerequisites and corequisites are lists of lists\n",
    "        for key in [\"prerequisites\", \"corequisites\"]:\n",
    "            if not isinstance(validated[key], list):\n",
    "                validated[key] = []\n",
    "            else:\n",
    "                cleaned_list = []\n",
    "                for item in validated[key]:\n",
    "                    if isinstance(item, list):\n",
    "                        cleaned_list.append(item)\n",
    "                    elif isinstance(item, str):\n",
    "                        cleaned_list.append([item])\n",
    "                validated[key] = cleaned_list\n",
    "        \n",
    "        if not isinstance(validated[\"grade_requirements\"], dict):\n",
    "            validated[\"grade_requirements\"] = {}\n",
    "        \n",
    "        return validated\n",
    "    \n",
    "    def _fallback_parse(self, raw: str) -> dict:\n",
    "        \"\"\"Basic fallback parser if API fails.\"\"\"\n",
    "        course_pattern = re.compile(r'\\b[A-Z]{2,5}\\s?\\d{2,3}[A-Z]?\\d?[A-Z]?\\b')\n",
    "        courses = course_pattern.findall(raw)\n",
    "        \n",
    "        normalized_courses = []\n",
    "        for course in courses:\n",
    "            if ' ' not in course:\n",
    "                course = re.sub(r'([A-Z]+)(\\d)', r'\\1 \\2', course)\n",
    "            normalized_courses.append(course)\n",
    "        \n",
    "        prerequisites = [[course] for course in normalized_courses]\n",
    "        \n",
    "        grade_requirements = {}\n",
    "        if 'C or better' in raw or 'grade of C' in raw:\n",
    "            for course in normalized_courses:\n",
    "                grade_requirements[course.replace(' ', '')] = 'C'\n",
    "        \n",
    "        note = None\n",
    "        if 'permission' in raw.lower() or 'instructor' in raw.lower():\n",
    "            note = \"Permission of instructor may be required\"\n",
    "        \n",
    "        return {\n",
    "            \"prerequisites\": prerequisites,\n",
    "            \"corequisites\": [],\n",
    "            \"grade_requirements\": grade_requirements,\n",
    "            \"requisites_note\": note\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f48d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Scraping functions\n",
    "def get_department_links(only=None):\n",
    "    \"\"\"Scrape all department links from the main courses page.\"\"\"\n",
    "    response = requests.get(COURSE_INDEX_URL)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    index_div = soup.find(\"div\", {\"id\": \"atozindex\"})\n",
    "    links = []\n",
    "\n",
    "    for a in index_div.find_all(\"a\", href=True):\n",
    "        dept_code = a['href'].split(\"/\")[-2].upper()\n",
    "        if only is None or dept_code in only:\n",
    "            links.append((dept_code, urljoin(BASE_URL, a['href'])))\n",
    "\n",
    "    return links\n",
    "\n",
    "def parse_course_block(block, parser: RequisiteParser):\n",
    "    \"\"\"Parse a course block from the HTML.\"\"\"\n",
    "    data = {\n",
    "        \"department\": None,\n",
    "        \"course_number\": None,\n",
    "        \"course_name\": None,\n",
    "        \"credits\": None,\n",
    "        \"description\": None,\n",
    "        \"requisites\": {\"prerequisites\": [], \"corequisites\": []},\n",
    "        \"grade_requirements\": {},\n",
    "        \"requisites_note\": None,\n",
    "        \"gen_ed\": None,\n",
    "        \"grading_status\": None,\n",
    "        \"repeat_rules\": None\n",
    "    }\n",
    "\n",
    "    # Header line\n",
    "    header = block.find(\"div\", class_=\"cols noindent\")\n",
    "    if header:\n",
    "        strong_tags = header.find_all(\"strong\")\n",
    "        if len(strong_tags) >= 3:\n",
    "            code = strong_tags[0].text.strip()\n",
    "            if \" \" in code:\n",
    "                data[\"department\"], data[\"course_number\"] = code.split(\" \", 1)\n",
    "                data[\"course_number\"] = data[\"course_number\"].rstrip(\".\")\n",
    "            data[\"course_id\"] = f\"{data['department']} {data['course_number']}\"\n",
    "            data[\"course_name\"] = strong_tags[1].text.strip()\n",
    "            data[\"credits\"] = strong_tags[2].text.strip().replace(\" Credits.\", \"\")\n",
    "\n",
    "    # Description\n",
    "    desc_block = block.find(\"p\", class_=\"courseblockextra\")\n",
    "    if desc_block:\n",
    "        data[\"description\"] = desc_block.text.strip()\n",
    "\n",
    "    # Requisites - using LLM parser\n",
    "    req_span = block.find(\"span\", class_=\"text detail-requisites margin--default\")\n",
    "    if req_span:\n",
    "        course_id = data.get(\"course_id\", \"Unknown\")\n",
    "        req_data = parser.parse_requisites(req_span.text, course_id)\n",
    "        data[\"requisites\"] = {\n",
    "            \"prerequisites\": req_data[\"prerequisites\"],\n",
    "            \"corequisites\": req_data[\"corequisites\"]\n",
    "        }\n",
    "        data[\"grade_requirements\"] = req_data[\"grade_requirements\"]\n",
    "        data[\"requisites_note\"] = req_data[\"requisites_note\"]\n",
    "\n",
    "    # Gen Ed - parse structured format\n",
    "    idea_span = block.find(\"span\", class_=\"text detail-idea_action margin--default\")\n",
    "    if idea_span:\n",
    "        gen_ed_text = idea_span.text.strip().replace(\"IDEAs in Action Gen Ed:\", \"\").strip()\n",
    "        data[\"gen_ed\"] = parse_gen_ed_requirements(gen_ed_text)\n",
    "\n",
    "    # Grading\n",
    "    grading_span = block.find(\"span\", class_=\"text detail-grading_status margin--default\")\n",
    "    if grading_span:\n",
    "        data[\"grading_status\"] = grading_span.text.strip().replace(\"Grading Status: \", \"\")\n",
    "    \n",
    "    # Repeat Rules - parse repeat information\n",
    "    repeat_span = block.find(\"span\", class_=\"text detail-repeat_rules margin--default\")\n",
    "    if repeat_span:\n",
    "        data[\"repeat_rules\"] = parse_repeat_rules(repeat_span.text.strip())\n",
    "\n",
    "    return data\n",
    "\n",
    "def parse_repeat_rules(repeat_text: str) -> Dict[str, any]:\n",
    "    \"\"\"\n",
    "    Parse repeat rules text into structured format.\n",
    "    \n",
    "    Example inputs:\n",
    "    - \"Repeat Rules: May be repeated for credit. 9 total credits. 3 total completions.\"\n",
    "    - \"Repeat Rules: May be repeated for credit.\"\n",
    "    \n",
    "    Returns dict with:\n",
    "    - repeatable: bool\n",
    "    - max_credits: int or None\n",
    "    - max_completions: int or None\n",
    "    \"\"\"\n",
    "    if not repeat_text:\n",
    "        return None\n",
    "    \n",
    "    # Remove \"Repeat Rules:\" prefix if present\n",
    "    repeat_text = repeat_text.replace(\"Repeat Rules:\", \"\").strip()\n",
    "    \n",
    "    result = {\n",
    "        \"repeatable\": False,\n",
    "        \"max_credits\": None,\n",
    "        \"max_completions\": None,\n",
    "        \"raw_text\": repeat_text\n",
    "    }\n",
    "    \n",
    "    # Check if repeatable\n",
    "    if \"may be repeated\" in repeat_text.lower():\n",
    "        result[\"repeatable\"] = True\n",
    "        \n",
    "        # Extract max credits\n",
    "        credits_match = re.search(r'(\\d+)\\s*total\\s*credits?', repeat_text, re.IGNORECASE)\n",
    "        if credits_match:\n",
    "            result[\"max_credits\"] = int(credits_match.group(1))\n",
    "        \n",
    "        # Extract max completions\n",
    "        completions_match = re.search(r'(\\d+)\\s*total\\s*completions?', repeat_text, re.IGNORECASE)\n",
    "        if completions_match:\n",
    "            result[\"max_completions\"] = int(completions_match.group(1))\n",
    "    \n",
    "    return result\n",
    "\n",
    "def parse_gen_ed_requirements(gen_ed_text: str):\n",
    "    \"\"\"\n",
    "    Parse gen ed requirements with AND/OR logic.\n",
    "    \n",
    "    Examples:\n",
    "    - \"FY-SEMINAR, FC-PAST or FC-POWER\" -> [[\"FY-SEMINAR\"], [\"FC-PAST\", \"FC-POWER\"]]\n",
    "    - \"FY-SEMINAR\" -> [[\"FY-SEMINAR\"]]\n",
    "    - \"FC-PAST or FC-POWER\" -> [[\"FC-PAST\", \"FC-POWER\"]]\n",
    "    \n",
    "    Returns a list of lists where:\n",
    "    - Outer list items are AND'ed (all required)\n",
    "    - Inner list items are OR'ed (choose one)\n",
    "    \"\"\"\n",
    "    if not gen_ed_text:\n",
    "        return []\n",
    "    \n",
    "    # Split by commas for AND groups\n",
    "    and_groups = [group.strip() for group in gen_ed_text.split(',')]\n",
    "    \n",
    "    result = []\n",
    "    for group in and_groups:\n",
    "        # Check if this group has OR options\n",
    "        if ' or ' in group.lower():\n",
    "            # Split by 'or' for OR options\n",
    "            or_options = [opt.strip() for opt in re.split(r'\\s+or\\s+', group, flags=re.IGNORECASE)]\n",
    "            result.append(or_options)\n",
    "        else:\n",
    "            # Single requirement\n",
    "            result.append([group])\n",
    "    \n",
    "    return result\n",
    "\n",
    "def parse_department(url, parser: RequisiteParser, dept_code: str, db_manager: DatabaseManager, mode: str = 'database'):\n",
    "    \"\"\"Parse all courses from a department page.\"\"\"\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    course_blocks = soup.find_all(\"div\", class_=\"courseblock\")\n",
    "    \n",
    "    total_courses = len(course_blocks)\n",
    "    print(f\"   Found {total_courses} courses to parse\")\n",
    "    \n",
    "    courses = []\n",
    "    saved_count = 0\n",
    "    \n",
    "    for i, cb in enumerate(course_blocks, 1):\n",
    "        # Extract course ID for progress display\n",
    "        header = cb.find(\"div\", class_=\"cols noindent\")\n",
    "        course_id = \"Unknown\"\n",
    "        if header:\n",
    "            strong_tags = header.find_all(\"strong\")\n",
    "            if strong_tags:\n",
    "                course_id = strong_tags[0].text.strip()\n",
    "        \n",
    "        print(f\"   Processing {course_id} ({i}/{total_courses})...\", end='\\r')\n",
    "        \n",
    "        course_data = parse_course_block(cb, parser)\n",
    "        \n",
    "        # Save to database if in database mode\n",
    "        if mode in ['database', 'both'] and db_manager:\n",
    "            try:\n",
    "                db_manager.save_course(course_data)\n",
    "                saved_count += 1\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Failed to save {course_id}: {e}\")\n",
    "        \n",
    "        # Collect for JSON if needed\n",
    "        if mode in ['json', 'both']:\n",
    "            courses.append(course_data)\n",
    "    \n",
    "    print(f\"   âœ“ Completed all {total_courses} courses in {dept_code} (saved {saved_count} to database)     \")\n",
    "    return courses\n",
    "\n",
    "def scrape_all_courses(parser: RequisiteParser, db_manager: Optional[DatabaseManager] = None, \n",
    "                      only=None, mode='database', dry_run=False, update_existing=True):\n",
    "    \"\"\"\n",
    "    Scrape all courses with flexible output options.\n",
    "    \n",
    "    Args:\n",
    "        parser: RequisiteParser instance\n",
    "        db_manager: DatabaseManager instance (required for database mode)\n",
    "        only: Set of department codes to scrape (None for all)\n",
    "        mode: 'database', 'json', or 'both'\n",
    "        dry_run: If True, don't actually save anything\n",
    "        update_existing: If True, update existing courses; if False, skip them\n",
    "    \"\"\"\n",
    "    department_links = get_department_links(only=only)\n",
    "    all_courses = {}\n",
    "    \n",
    "    print(f\"\\nðŸŽ¯ Starting scrape of {len(department_links)} departments\")\n",
    "    print(f\"   Mode: {mode}\")\n",
    "    print(f\"   Dry run: {dry_run}\")\n",
    "    print(f\"   Update existing: {update_existing}\\n\")\n",
    "    \n",
    "    overall_start_time = time.time()\n",
    "\n",
    "    for dept_idx, (dept_code, url) in enumerate(department_links, 1):\n",
    "        try:\n",
    "            print(f\"ðŸ“š [{dept_idx}/{len(department_links)}] Scraping {dept_code}...\")\n",
    "            dept_start_time = time.time()\n",
    "            \n",
    "            # Begin transaction for this department\n",
    "            if db_manager and not dry_run:\n",
    "                db_manager.conn.commit()  # Commit any pending changes\n",
    "            \n",
    "            courses = parse_department(url, parser, dept_code, db_manager if not dry_run else None, mode)\n",
    "            \n",
    "            if mode in ['json', 'both']:\n",
    "                all_courses[dept_code] = courses\n",
    "            \n",
    "            # Commit department transaction\n",
    "            if db_manager and not dry_run and mode in ['database', 'both']:\n",
    "                db_manager.commit()\n",
    "            \n",
    "            dept_elapsed = time.time() - dept_start_time\n",
    "            print(f\"âœ… Successfully scraped {dept_code} in {dept_elapsed/60:.1f} minutes\\n\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error scraping {dept_code}: {e}\\n\")\n",
    "            if db_manager and not dry_run:\n",
    "                db_manager.rollback()\n",
    "    \n",
    "    overall_elapsed = time.time() - overall_start_time\n",
    "    print(f\"â±ï¸  Total scraping time: {overall_elapsed/60:.1f} minutes\")\n",
    "    \n",
    "    return all_courses\n",
    "\n",
    "def save_to_json(data, filename=\"unc_courses.json\"):\n",
    "    \"\"\"Save course data to JSON file.\"\"\"\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, indent=2, ensure_ascii=False)\n",
    "    print(f\"\\nðŸ’¾ Saved to {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9fb77b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-22 22:45:56,830 - INFO - Loaded 152 departments and 10212 courses into cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸŽ¯ Starting scrape of 152 departments\n",
      "   Mode: database\n",
      "   Dry run: False\n",
      "   Update existing: True\n",
      "\n",
      "ðŸ“š [1/152] Scraping AERO...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-22 22:45:57,428 - ERROR - Error saving course AERO 101: not all arguments converted during string formatting\n",
      "2025-07-22 22:45:57,429 - ERROR - Failed to save AERO 101.: not all arguments converted during string formatting\n",
      "2025-07-22 22:45:57,430 - ERROR - Error saving course AERO 102: not all arguments converted during string formatting\n",
      "2025-07-22 22:45:57,431 - ERROR - Failed to save AERO 102.: not all arguments converted during string formatting\n",
      "2025-07-22 22:45:57,433 - ERROR - Error saving course AERO 190: not all arguments converted during string formatting\n",
      "2025-07-22 22:45:57,434 - ERROR - Failed to save AERO 190.: not all arguments converted during string formatting\n",
      "2025-07-22 22:45:57,435 - ERROR - Error saving course AERO 196: not all arguments converted during string formatting\n",
      "2025-07-22 22:45:57,435 - ERROR - Failed to save AERO 196.: not all arguments converted during string formatting\n",
      "2025-07-22 22:45:57,437 - ERROR - Error saving course AERO 201: not all arguments converted during string formatting\n",
      "2025-07-22 22:45:57,437 - ERROR - Failed to save AERO 201.: not all arguments converted during string formatting\n",
      "2025-07-22 22:45:57,439 - ERROR - Error saving course AERO 202: not all arguments converted during string formatting\n",
      "2025-07-22 22:45:57,439 - ERROR - Failed to save AERO 202.: not all arguments converted during string formatting\n",
      "2025-07-22 22:45:57,441 - ERROR - Error saving course AERO 213: not all arguments converted during string formatting\n",
      "2025-07-22 22:45:57,442 - ERROR - Failed to save AERO 213.: not all arguments converted during string formatting\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Found 13 courses to parse\n",
      "   Processing AERO 301. (8/13)...\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-22 22:46:01,787 - ERROR - Error saving course AERO 301: not all arguments converted during string formatting\n",
      "2025-07-22 22:46:01,787 - ERROR - Failed to save AERO 301.: not all arguments converted during string formatting\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Processing AERO 302. (9/13)...\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-22 22:46:04,623 - ERROR - Error saving course AERO 302: not all arguments converted during string formatting\n",
      "2025-07-22 22:46:04,623 - ERROR - Failed to save AERO 302.: not all arguments converted during string formatting\n",
      "2025-07-22 22:46:04,625 - ERROR - Error saving course AERO 393: not all arguments converted during string formatting\n",
      "2025-07-22 22:46:04,625 - ERROR - Failed to save AERO 393.: not all arguments converted during string formatting\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Processing AERO 401. (11/13)...\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 25\u001b[39m\n\u001b[32m      9\u001b[39m UPDATE_EXISTING = \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# Set to False to skip existing courses\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Option 1: Scrape sample departments\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# sample_departments = {\"COMP\", \"BIOL\", \"CHEM\"}\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# courses = scrape_all_courses(\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     23\u001b[39m \n\u001b[32m     24\u001b[39m \u001b[38;5;66;03m# Option 2: Scrape all departments\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m courses = \u001b[43mscrape_all_courses\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparser\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdb_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mMODE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m MODE \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m'\u001b[39m\u001b[33mjson\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mboth\u001b[39m\u001b[33m'\u001b[39m] \u001b[38;5;129;01mand\u001b[39;00m courses:\n\u001b[32m     27\u001b[39m     save_to_json(courses, \u001b[33m\"\u001b[39m\u001b[33munc_courses.json\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 234\u001b[39m, in \u001b[36mscrape_all_courses\u001b[39m\u001b[34m(parser, db_manager, only, mode, dry_run, update_existing)\u001b[39m\n\u001b[32m    231\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m db_manager \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m dry_run:\n\u001b[32m    232\u001b[39m     db_manager.conn.commit()  \u001b[38;5;66;03m# Commit any pending changes\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m234\u001b[39m courses = \u001b[43mparse_department\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparser\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdept_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdb_manager\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdry_run\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    236\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m'\u001b[39m\u001b[33mjson\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mboth\u001b[39m\u001b[33m'\u001b[39m]:\n\u001b[32m    237\u001b[39m     all_courses[dept_code] = courses\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 185\u001b[39m, in \u001b[36mparse_department\u001b[39m\u001b[34m(url, parser, dept_code, db_manager, mode)\u001b[39m\n\u001b[32m    181\u001b[39m         course_id = strong_tags[\u001b[32m0\u001b[39m].text.strip()\n\u001b[32m    183\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m   Processing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcourse_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_courses\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)...\u001b[39m\u001b[33m\"\u001b[39m, end=\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m185\u001b[39m course_data = \u001b[43mparse_course_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparser\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    187\u001b[39m \u001b[38;5;66;03m# Save to database if in database mode\u001b[39;00m\n\u001b[32m    188\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m'\u001b[39m\u001b[33mdatabase\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mboth\u001b[39m\u001b[33m'\u001b[39m] \u001b[38;5;129;01mand\u001b[39;00m db_manager:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 54\u001b[39m, in \u001b[36mparse_course_block\u001b[39m\u001b[34m(block, parser)\u001b[39m\n\u001b[32m     52\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m req_span:\n\u001b[32m     53\u001b[39m     course_id = data.get(\u001b[33m\"\u001b[39m\u001b[33mcourse_id\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mUnknown\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m     req_data = \u001b[43mparser\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparse_requisites\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq_span\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcourse_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m     data[\u001b[33m\"\u001b[39m\u001b[33mrequisites\u001b[39m\u001b[33m\"\u001b[39m] = {\n\u001b[32m     56\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mprerequisites\u001b[39m\u001b[33m\"\u001b[39m: req_data[\u001b[33m\"\u001b[39m\u001b[33mprerequisites\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m     57\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mcorequisites\u001b[39m\u001b[33m\"\u001b[39m: req_data[\u001b[33m\"\u001b[39m\u001b[33mcorequisites\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     58\u001b[39m     }\n\u001b[32m     59\u001b[39m     data[\u001b[33m\"\u001b[39m\u001b[33mgrade_requirements\u001b[39m\u001b[33m\"\u001b[39m] = req_data[\u001b[33m\"\u001b[39m\u001b[33mgrade_requirements\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 112\u001b[39m, in \u001b[36mRequisiteParser.parse_requisites\u001b[39m\u001b[34m(self, raw, course_id)\u001b[39m\n\u001b[32m     31\u001b[39m         prompt = \u001b[33mf\u001b[39m\u001b[33m\"\"\"\u001b[39m\u001b[33mParse the following course requisite statement and return a JSON object with this exact structure:\u001b[39m\n\u001b[32m     32\u001b[39m \n\u001b[32m     33\u001b[39m \u001b[38;5;130;01m{{\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    108\u001b[39m \n\u001b[32m    109\u001b[39m \u001b[33mReturn ONLY the JSON object, no explanation or markdown.\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m    111\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m112\u001b[39m             response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    113\u001b[39m             json_text = response.text.strip()\n\u001b[32m    114\u001b[39m             json_text = re.sub(\u001b[33mr\u001b[39m\u001b[33m'\u001b[39m\u001b[33m^```json\u001b[39m\u001b[33m\\\u001b[39m\u001b[33ms*\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m, json_text)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\malac\\anaconda3\\envs\\pathfinder\\Lib\\site-packages\\google\\generativeai\\generative_models.py:331\u001b[39m, in \u001b[36mGenerativeModel.generate_content\u001b[39m\u001b[34m(self, contents, generation_config, safety_settings, stream, tools, tool_config, request_options)\u001b[39m\n\u001b[32m    329\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m generation_types.GenerateContentResponse.from_iterator(iterator)\n\u001b[32m    330\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m331\u001b[39m         response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    332\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    333\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrequest_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    334\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    335\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m generation_types.GenerateContentResponse.from_response(response)\n\u001b[32m    336\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m google.api_core.exceptions.InvalidArgument \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\malac\\anaconda3\\envs\\pathfinder\\Lib\\site-packages\\google\\ai\\generativelanguage_v1beta\\services\\generative_service\\client.py:835\u001b[39m, in \u001b[36mGenerativeServiceClient.generate_content\u001b[39m\u001b[34m(self, request, model, contents, retry, timeout, metadata)\u001b[39m\n\u001b[32m    832\u001b[39m \u001b[38;5;28mself\u001b[39m._validate_universe_domain()\n\u001b[32m    834\u001b[39m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m835\u001b[39m response = \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    836\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    837\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    838\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    839\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    840\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    842\u001b[39m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[32m    843\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\malac\\anaconda3\\envs\\pathfinder\\Lib\\site-packages\\google\\api_core\\gapic_v1\\method.py:131\u001b[39m, in \u001b[36m_GapicCallable.__call__\u001b[39m\u001b[34m(self, timeout, retry, compression, *args, **kwargs)\u001b[39m\n\u001b[32m    128\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    129\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mcompression\u001b[39m\u001b[33m\"\u001b[39m] = compression\n\u001b[32m--> \u001b[39m\u001b[32m131\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\malac\\anaconda3\\envs\\pathfinder\\Lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:293\u001b[39m, in \u001b[36mRetry.__call__.<locals>.retry_wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    289\u001b[39m target = functools.partial(func, *args, **kwargs)\n\u001b[32m    290\u001b[39m sleep_generator = exponential_sleep_generator(\n\u001b[32m    291\u001b[39m     \u001b[38;5;28mself\u001b[39m._initial, \u001b[38;5;28mself\u001b[39m._maximum, multiplier=\u001b[38;5;28mself\u001b[39m._multiplier\n\u001b[32m    292\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m293\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    294\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    295\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    296\u001b[39m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    297\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    298\u001b[39m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m=\u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    299\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\malac\\anaconda3\\envs\\pathfinder\\Lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:144\u001b[39m, in \u001b[36mretry_target\u001b[39m\u001b[34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[39m\n\u001b[32m    142\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m sleep \u001b[38;5;129;01min\u001b[39;00m sleep_generator:\n\u001b[32m    143\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m144\u001b[39m         result = \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    145\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m inspect.isawaitable(result):\n\u001b[32m    146\u001b[39m             warnings.warn(_ASYNC_RETRY_WARNING)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\malac\\anaconda3\\envs\\pathfinder\\Lib\\site-packages\\google\\api_core\\timeout.py:130\u001b[39m, in \u001b[36mTimeToDeadlineTimeout.__call__.<locals>.func_with_timeout\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    126\u001b[39m         remaining_timeout = \u001b[38;5;28mself\u001b[39m._timeout\n\u001b[32m    128\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m] = remaining_timeout\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\malac\\anaconda3\\envs\\pathfinder\\Lib\\site-packages\\google\\api_core\\grpc_helpers.py:76\u001b[39m, in \u001b[36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     73\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(callable_)\n\u001b[32m     74\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34merror_remapped_callable\u001b[39m(*args, **kwargs):\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcallable_\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     77\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m grpc.RpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     78\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m exceptions.from_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\malac\\anaconda3\\envs\\pathfinder\\Lib\\site-packages\\grpc\\_interceptor.py:277\u001b[39m, in \u001b[36m_UnaryUnaryMultiCallable.__call__\u001b[39m\u001b[34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[39m\n\u001b[32m    268\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\n\u001b[32m    269\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    270\u001b[39m     request: Any,\n\u001b[32m   (...)\u001b[39m\u001b[32m    275\u001b[39m     compression: Optional[grpc.Compression] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    276\u001b[39m ) -> Any:\n\u001b[32m--> \u001b[39m\u001b[32m277\u001b[39m     response, ignored_call = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_with_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    278\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    279\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    280\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    281\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    282\u001b[39m \u001b[43m        \u001b[49m\u001b[43mwait_for_ready\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwait_for_ready\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    283\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    284\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    285\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\malac\\anaconda3\\envs\\pathfinder\\Lib\\site-packages\\grpc\\_interceptor.py:329\u001b[39m, in \u001b[36m_UnaryUnaryMultiCallable._with_call\u001b[39m\u001b[34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[39m\n\u001b[32m    326\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[32m    327\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m _FailureOutcome(exception, sys.exc_info()[\u001b[32m2\u001b[39m])\n\u001b[32m--> \u001b[39m\u001b[32m329\u001b[39m call = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_interceptor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mintercept_unary_unary\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    330\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontinuation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclient_call_details\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\n\u001b[32m    331\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    332\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m call.result(), call\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\malac\\anaconda3\\envs\\pathfinder\\Lib\\site-packages\\google\\ai\\generativelanguage_v1beta\\services\\generative_service\\transports\\grpc.py:79\u001b[39m, in \u001b[36m_LoggingClientInterceptor.intercept_unary_unary\u001b[39m\u001b[34m(self, continuation, client_call_details, request)\u001b[39m\n\u001b[32m     64\u001b[39m     grpc_request = {\n\u001b[32m     65\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mpayload\u001b[39m\u001b[33m\"\u001b[39m: request_payload,\n\u001b[32m     66\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mrequestMethod\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mgrpc\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     67\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mdict\u001b[39m(request_metadata),\n\u001b[32m     68\u001b[39m     }\n\u001b[32m     69\u001b[39m     _LOGGER.debug(\n\u001b[32m     70\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSending request for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclient_call_details.method\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     71\u001b[39m         extra={\n\u001b[32m   (...)\u001b[39m\u001b[32m     76\u001b[39m         },\n\u001b[32m     77\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m79\u001b[39m response = \u001b[43mcontinuation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclient_call_details\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m logging_enabled:  \u001b[38;5;66;03m# pragma: NO COVER\u001b[39;00m\n\u001b[32m     81\u001b[39m     response_metadata = response.trailing_metadata()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\malac\\anaconda3\\envs\\pathfinder\\Lib\\site-packages\\grpc\\_interceptor.py:315\u001b[39m, in \u001b[36m_UnaryUnaryMultiCallable._with_call.<locals>.continuation\u001b[39m\u001b[34m(new_details, request)\u001b[39m\n\u001b[32m    306\u001b[39m (\n\u001b[32m    307\u001b[39m     new_method,\n\u001b[32m    308\u001b[39m     new_timeout,\n\u001b[32m   (...)\u001b[39m\u001b[32m    312\u001b[39m     new_compression,\n\u001b[32m    313\u001b[39m ) = _unwrap_client_call_details(new_details, client_call_details)\n\u001b[32m    314\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m315\u001b[39m     response, call = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_thunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_method\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwith_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    316\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    317\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnew_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    318\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnew_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    319\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnew_credentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    320\u001b[39m \u001b[43m        \u001b[49m\u001b[43mwait_for_ready\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnew_wait_for_ready\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    321\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnew_compression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    322\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    323\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _UnaryOutcome(response, call)\n\u001b[32m    324\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m grpc.RpcError \u001b[38;5;28;01mas\u001b[39;00m rpc_error:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\malac\\anaconda3\\envs\\pathfinder\\Lib\\site-packages\\grpc\\_channel.py:1195\u001b[39m, in \u001b[36m_UnaryUnaryMultiCallable.with_call\u001b[39m\u001b[34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[39m\n\u001b[32m   1183\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwith_call\u001b[39m(\n\u001b[32m   1184\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1185\u001b[39m     request: Any,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1190\u001b[39m     compression: Optional[grpc.Compression] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1191\u001b[39m ) -> Tuple[Any, grpc.Call]:\n\u001b[32m   1192\u001b[39m     (\n\u001b[32m   1193\u001b[39m         state,\n\u001b[32m   1194\u001b[39m         call,\n\u001b[32m-> \u001b[39m\u001b[32m1195\u001b[39m     ) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_blocking\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1196\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwait_for_ready\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompression\u001b[49m\n\u001b[32m   1197\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1198\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _end_unary_response_blocking(state, call, \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\malac\\anaconda3\\envs\\pathfinder\\Lib\\site-packages\\grpc\\_channel.py:1162\u001b[39m, in \u001b[36m_UnaryUnaryMultiCallable._blocking\u001b[39m\u001b[34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[39m\n\u001b[32m   1145\u001b[39m state.target = _common.decode(\u001b[38;5;28mself\u001b[39m._target)\n\u001b[32m   1146\u001b[39m call = \u001b[38;5;28mself\u001b[39m._channel.segregated_call(\n\u001b[32m   1147\u001b[39m     cygrpc.PropagationConstants.GRPC_PROPAGATE_DEFAULTS,\n\u001b[32m   1148\u001b[39m     \u001b[38;5;28mself\u001b[39m._method,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1160\u001b[39m     \u001b[38;5;28mself\u001b[39m._registered_call_handle,\n\u001b[32m   1161\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1162\u001b[39m event = \u001b[43mcall\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnext_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1163\u001b[39m _handle_event(event, state, \u001b[38;5;28mself\u001b[39m._response_deserializer)\n\u001b[32m   1164\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m state, call\n",
      "\u001b[36mFile \u001b[39m\u001b[32msrc\\\\python\\\\grpcio\\\\grpc\\\\_cython\\\\_cygrpc/channel.pyx.pxi:388\u001b[39m, in \u001b[36mgrpc._cython.cygrpc.SegregatedCall.next_event\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32msrc\\\\python\\\\grpcio\\\\grpc\\\\_cython\\\\_cygrpc/channel.pyx.pxi:211\u001b[39m, in \u001b[36mgrpc._cython.cygrpc._next_call_event\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32msrc\\\\python\\\\grpcio\\\\grpc\\\\_cython\\\\_cygrpc/channel.pyx.pxi:205\u001b[39m, in \u001b[36mgrpc._cython.cygrpc._next_call_event\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32msrc\\\\python\\\\grpcio\\\\grpc\\\\_cython\\\\_cygrpc/completion_queue.pyx.pxi:78\u001b[39m, in \u001b[36mgrpc._cython.cygrpc._latent_event\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32msrc\\\\python\\\\grpcio\\\\grpc\\\\_cython\\\\_cygrpc/completion_queue.pyx.pxi:62\u001b[39m, in \u001b[36mgrpc._cython.cygrpc._internal_latent_event\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32msrc\\\\python\\\\grpcio\\\\grpc\\\\_cython\\\\_cygrpc/completion_queue.pyx.pxi:58\u001b[39m, in \u001b[36mgrpc._cython.cygrpc._interpret_event\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32msrc\\\\python\\\\grpcio\\\\grpc\\\\_cython\\\\_cygrpc/tag.pyx.pxi:71\u001b[39m, in \u001b[36mgrpc._cython.cygrpc._BatchOperationTag.event\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32msrc\\\\python\\\\grpcio\\\\grpc\\\\_cython\\\\_cygrpc/operation.pyx.pxi:138\u001b[39m, in \u001b[36mgrpc._cython.cygrpc.ReceiveInitialMetadataOperation.un_c\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32msrc\\\\python\\\\grpcio\\\\grpc\\\\_cython\\\\_cygrpc/metadata.pyx.pxi:69\u001b[39m, in \u001b[36mgrpc._cython.cygrpc._metadata\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32msrc\\\\python\\\\grpcio\\\\grpc\\\\_cython\\\\_cygrpc/metadata.pyx.pxi:70\u001b[39m, in \u001b[36mgenexpr\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32msrc\\\\python\\\\grpcio\\\\grpc\\\\_cython\\\\_cygrpc/metadata.pyx.pxi:64\u001b[39m, in \u001b[36mgrpc._cython.cygrpc._metadatum\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<string>:1\u001b[39m, in \u001b[36m<lambda>\u001b[39m\u001b[34m(_cls, key, value)\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Cell 6: Main execution\n",
    "# Initialize components\n",
    "parser = RequisiteParser(model=\"gemini-2.5-flash\", delay=0.5)\n",
    "db_manager = DatabaseManager(DATABASE_URL)\n",
    "\n",
    "# Configuration options\n",
    "MODE = 'database'  # 'database', 'json', or 'both'\n",
    "DRY_RUN = False    # Set to True to test without saving\n",
    "UPDATE_EXISTING = True  # Set to False to skip existing courses\n",
    "\n",
    "# Option 1: Scrape sample departments\n",
    "# sample_departments = {\"COMP\", \"BIOL\", \"CHEM\"}\n",
    "# courses = scrape_all_courses(\n",
    "#     parser, \n",
    "#     db_manager,\n",
    "#     only=sample_departments,\n",
    "#     mode=MODE,\n",
    "#     dry_run=DRY_RUN,\n",
    "#     update_existing=UPDATE_EXISTING\n",
    "# )\n",
    "# if MODE in ['json', 'both'] and courses:\n",
    "#     save_to_json(courses, \"unc_courses_sample.json\")\n",
    "\n",
    "# Option 2: Scrape all departments (uncomment to use)\n",
    "courses = scrape_all_courses(parser, db_manager, mode=MODE)\n",
    "if MODE in ['json', 'both'] and courses:\n",
    "    save_to_json(courses, \"unc_courses.json\")\n",
    "\n",
    "# Print statistics\n",
    "print(f\"\\nðŸ“Š Statistics:\")\n",
    "print(f\"   Total API calls: {parser.api_calls}\")\n",
    "print(f\"   Failed parses: {len(parser.failed_parses)}\")\n",
    "if parser.failed_parses:\n",
    "    print(\"\\nâš ï¸  Failed to parse requisites for:\")\n",
    "    for course_id, error in parser.failed_parses[:5]:\n",
    "        print(f\"   - {course_id}: {error[:50]}...\")\n",
    "    if len(parser.failed_parses) > 5:\n",
    "        print(f\"   ... and {len(parser.failed_parses) - 5} more\")\n",
    "\n",
    "# Close database connection\n",
    "db_manager.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28faaee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ” Database Contents:\n",
      "   Total courses: 10212\n",
      "   Courses with prerequisites: 2405\n",
      "\n",
      "ðŸ“š Sample courses:\n",
      "   COMP 110: Introduction to Programming.\n",
      "   COMP 211: Systems Fundamentals.\n",
      "      Prerequisites: 1 groups\n",
      "   BIOL 101: Principles of Biology.\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Database verification\n",
    "def verify_scraping_results():\n",
    "    \"\"\"Verify what was scraped into the database.\"\"\"\n",
    "    from db_queries import CourseDatabase\n",
    "    \n",
    "    with CourseDatabase() as db:\n",
    "        stats = db.get_database_stats()\n",
    "        print(\"\\nðŸ” Database Contents:\")\n",
    "        print(f\"   Total courses: {stats['total_courses']}\")\n",
    "        print(f\"   Courses with prerequisites: {stats['courses_with_prereqs']}\")\n",
    "        \n",
    "        # Show sample courses\n",
    "        print(\"\\nðŸ“š Sample courses:\")\n",
    "        sample_courses = [\"COMP 110\", \"COMP 211\", \"BIOL 101\"]\n",
    "        for course_id in sample_courses:\n",
    "            course = db.get_course(course_id)\n",
    "            if course:\n",
    "                prereqs = db.get_course_prerequisites(course_id)\n",
    "                print(f\"   {course_id}: {course['name']}\")\n",
    "                if prereqs['prerequisites']:\n",
    "                    print(f\"      Prerequisites: {len(prereqs['prerequisites'])} groups\")\n",
    "\n",
    "# Run verification\n",
    "verify_scraping_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e465a4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” Analyzing 152 departments...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning departments: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 152/152 [01:12<00:00,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š Requisite Analysis Complete!\n",
      "\n",
      "Total courses across all departments: 10212\n",
      "Courses with requisites: 2759\n",
      "Courses without requisites: 7453\n",
      "Percentage with requisites: 27.0%\n",
      "\n",
      "ðŸ’¡ You will need 2759 API calls\n",
      "â±ï¸  Estimated time at 2.1s/call: 96.6 minutes\n",
      "\n",
      "ðŸ“ˆ Top 10 departments by requisite count:\n",
      "   BIOL: 167/264 courses (63%)\n",
      "   PSYC: 101/183 courses (55%)\n",
      "   NURS: 91/169 courses (54%)\n",
      "   ECON: 81/145 courses (56%)\n",
      "   COMP: 79/109 courses (72%)\n",
      "   PHCY: 75/112 courses (67%)\n",
      "   CHEM: 74/112 courses (66%)\n",
      "   SPAN: 71/119 courses (60%)\n",
      "   MATH: 70/110 courses (64%)\n",
      "   COMM: 69/213 courses (32%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell to count non-empty requisites across all departments\n",
    "def count_requisites(only=None):\n",
    "    \"\"\"Count how many courses have non-empty requisites across departments.\"\"\"\n",
    "    department_links = get_department_links(only=only)\n",
    "    \n",
    "    total_courses = 0\n",
    "    courses_with_requisites = 0\n",
    "    dept_stats = {}\n",
    "    \n",
    "    print(f\"ðŸ” Analyzing {len(department_links)} departments...\\n\")\n",
    "    \n",
    "    for dept_code, url in tqdm(department_links, desc=\"Scanning departments\"):\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        course_blocks = soup.find_all(\"div\", class_=\"courseblock\")\n",
    "        \n",
    "        dept_total = len(course_blocks)\n",
    "        dept_with_reqs = 0\n",
    "        \n",
    "        for block in course_blocks:\n",
    "            req_span = block.find(\"span\", class_=\"text detail-requisites margin--default\")\n",
    "            if req_span and req_span.text.strip() and req_span.text.strip() != \"Requisites:\":\n",
    "                dept_with_reqs += 1\n",
    "        \n",
    "        dept_stats[dept_code] = {\n",
    "            \"total\": dept_total,\n",
    "            \"with_requisites\": dept_with_reqs,\n",
    "            \"percentage\": (dept_with_reqs / dept_total * 100) if dept_total > 0 else 0\n",
    "        }\n",
    "        \n",
    "        total_courses += dept_total\n",
    "        courses_with_requisites += dept_with_reqs\n",
    "    \n",
    "    # Print summary\n",
    "    print(f\"\\nðŸ“Š Requisite Analysis Complete!\\n\")\n",
    "    print(f\"Total courses across all departments: {total_courses}\")\n",
    "    print(f\"Courses with requisites: {courses_with_requisites}\")\n",
    "    print(f\"Courses without requisites: {total_courses - courses_with_requisites}\")\n",
    "    print(f\"Percentage with requisites: {courses_with_requisites/total_courses*100:.1f}%\")\n",
    "    print(f\"\\nðŸ’¡ You will need {courses_with_requisites} API calls\")\n",
    "    print(f\"â±ï¸  Estimated time at 2.1s/call: {courses_with_requisites * 2.1 / 60:.1f} minutes\")\n",
    "    \n",
    "    # Show top departments by requisite count\n",
    "    print(f\"\\nðŸ“ˆ Top 10 departments by requisite count:\")\n",
    "    sorted_depts = sorted(dept_stats.items(), key=lambda x: x[1]['with_requisites'], reverse=True)[:10]\n",
    "    for dept, stats in sorted_depts:\n",
    "        print(f\"   {dept}: {stats['with_requisites']}/{stats['total']} courses ({stats['percentage']:.0f}%)\")\n",
    "    \n",
    "    return dept_stats\n",
    "\n",
    "# Run the analysis\n",
    "# For all departments:\n",
    "dept_stats = count_requisites()\n",
    "\n",
    "# Or for specific departments:\n",
    "# dept_stats = count_requisites(only={\"COMP\", \"MATH\", \"BIOL\", \"CHEM\", \"PHYS\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pathfinder",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
