{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "79c3a9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Import and setup\n",
    "import re\n",
    "import json\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "from tqdm import tqdm\n",
    "import google.generativeai as genai\n",
    "import time\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import psycopg2\n",
    "from psycopg2.extras import RealDictCursor\n",
    "import logging\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Optional\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "344947c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Configure API and Database\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "DATABASE_URL = os.getenv(\"DATABASE_URL\")\n",
    "\n",
    "if not GEMINI_API_KEY:\n",
    "    raise ValueError(\"GEMINI_API_KEY not found in .env file\")\n",
    "\n",
    "if not DATABASE_URL:\n",
    "    raise ValueError(\"DATABASE_URL not found in .env file\")\n",
    "\n",
    "genai.configure(api_key=GEMINI_API_KEY)\n",
    "\n",
    "BASE_URL = \"https://catalog.unc.edu\"\n",
    "COURSE_INDEX_URL = f\"{BASE_URL}/courses/#text\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e2c1151b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Database Manager class\n",
    "class DatabaseManager:\n",
    "    def __init__(self, db_url: str):\n",
    "        \"\"\"Initialize database connection and caches.\"\"\"\n",
    "        # Parse the URL\n",
    "        from urllib.parse import urlparse\n",
    "        url = urlparse(db_url)\n",
    "        \n",
    "        conn_params = {\n",
    "            \"host\": url.hostname,\n",
    "            \"port\": url.port,\n",
    "            \"database\": url.path[1:],\n",
    "            \"user\": url.username,\n",
    "            \"password\": url.password,\n",
    "            \"sslmode\": \"require\",\n",
    "            \"gssencmode\": \"disable\"\n",
    "        }\n",
    "        \n",
    "        self.conn = psycopg2.connect(**conn_params)\n",
    "        self.conn.autocommit = False\n",
    "        self.cur = self.conn.cursor(cursor_factory=RealDictCursor)\n",
    "        \n",
    "        # Cache for lookups\n",
    "        self.department_cache = {}\n",
    "        self.course_id_cache = {}\n",
    "        \n",
    "        # Load existing data into cache\n",
    "        self._load_cache()\n",
    "    \n",
    "    def _load_cache(self):\n",
    "        \"\"\"Load existing departments and courses into cache.\"\"\"\n",
    "        # Load departments\n",
    "        self.cur.execute(\"SELECT id, code FROM departments\")\n",
    "        for row in self.cur.fetchall():\n",
    "            self.department_cache[row['code']] = row['id']\n",
    "        \n",
    "        # Load course IDs\n",
    "        self.cur.execute(\"SELECT id, course_id FROM courses\")\n",
    "        for row in self.cur.fetchall():\n",
    "            self.course_id_cache[row['course_id']] = row['id']\n",
    "        \n",
    "        logger.info(f\"Loaded {len(self.department_cache)} departments and {len(self.course_id_cache)} courses into cache\")\n",
    "    \n",
    "    def get_or_create_department(self, dept_code: str) -> int:\n",
    "        \"\"\"Get or create a department, returning its ID.\"\"\"\n",
    "        if dept_code in self.department_cache:\n",
    "            return self.department_cache[dept_code]\n",
    "        \n",
    "        self.cur.execute(\"\"\"\n",
    "            INSERT INTO departments (code) \n",
    "            VALUES (%s) \n",
    "            ON CONFLICT (code) DO UPDATE SET code = EXCLUDED.code\n",
    "            RETURNING id\n",
    "        \"\"\", (dept_code,))\n",
    "        \n",
    "        dept_id = self.cur.fetchone()['id']\n",
    "        self.department_cache[dept_code] = dept_id\n",
    "        return dept_id\n",
    "    \n",
    "    def save_course(self, course_data: Dict) -> Optional[int]:\n",
    "        \"\"\"Save a course to the database.\"\"\"\n",
    "        try:\n",
    "            dept_id = self.get_or_create_department(course_data['department'])\n",
    "            \n",
    "            # Extract repeat rules if present\n",
    "            repeatable = False\n",
    "            max_repeat_credits = None\n",
    "            max_repeat_completions = None\n",
    "            \n",
    "            if course_data.get('repeat_rules'):\n",
    "                repeat_rules = course_data['repeat_rules']\n",
    "                repeatable = repeat_rules.get('repeatable', False)\n",
    "                max_repeat_credits = repeat_rules.get('max_credits')\n",
    "                max_repeat_completions = repeat_rules.get('max_completions')\n",
    "            \n",
    "            # Insert or update course\n",
    "            self.cur.execute(\"\"\"\n",
    "                INSERT INTO courses \n",
    "                (course_id, department_id, course_number, name, description, \n",
    "                 credits, grading_status, requisites_note, repeatable, \n",
    "                 max_repeat_credits, max_repeat_completions)\n",
    "                VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "                ON CONFLICT (course_id) DO UPDATE SET\n",
    "                    name = EXCLUDED.name,\n",
    "                    description = EXCLUDED.description,\n",
    "                    credits = EXCLUDED.credits,\n",
    "                    grading_status = EXCLUDED.grading_status,\n",
    "                    requisites_note = EXCLUDED.requisites_note,\n",
    "                    repeatable = EXCLUDED.repeatable,\n",
    "                    max_repeat_credits = EXCLUDED.max_repeat_credits,\n",
    "                    max_repeat_completions = EXCLUDED.max_repeat_completions,\n",
    "                    updated_at = NOW()\n",
    "                RETURNING id\n",
    "            \"\"\", (\n",
    "                course_data['course_id'],\n",
    "                dept_id,\n",
    "                course_data['course_number'],\n",
    "                course_data['course_name'],\n",
    "                course_data.get('description'),\n",
    "                course_data.get('credits'),\n",
    "                course_data.get('grading_status'),\n",
    "                course_data.get('requisites_note'),\n",
    "                repeatable,\n",
    "                max_repeat_credits,\n",
    "                max_repeat_completions\n",
    "            ))\n",
    "            \n",
    "            course_db_id = self.cur.fetchone()['id']\n",
    "            self.course_id_cache[course_data['course_id']] = course_db_id\n",
    "            \n",
    "            # Save prerequisites if present\n",
    "            if course_data.get('requisites'):\n",
    "                self._save_prerequisites(course_db_id, course_data['requisites'])\n",
    "            \n",
    "            # Save grade requirements if present\n",
    "            if course_data.get('grade_requirements'):\n",
    "                self._save_grade_requirements(course_db_id, course_data['grade_requirements'])\n",
    "            \n",
    "            # Save gen ed fulfillments to normalized table\n",
    "            if course_data.get('gen_ed'):\n",
    "                self._save_gen_ed_fulfillments(course_db_id, course_data['gen_ed'])\n",
    "            \n",
    "            return course_db_id\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error saving course {course_data.get('course_id')}: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def _save_gen_ed_fulfillments(self, course_db_id: int, gen_ed_groups: List[List[str]]):\n",
    "        \"\"\"Save gen ed fulfillments to normalized table.\"\"\"\n",
    "        # Clear existing fulfillments\n",
    "        self.cur.execute(\"DELETE FROM gen_ed_fulfillments WHERE course_id = %s\", (course_db_id,))\n",
    "        \n",
    "        # Save new fulfillments\n",
    "        for group_idx, group in enumerate(gen_ed_groups):\n",
    "            for gen_ed_code in group:\n",
    "                if gen_ed_code:  # Skip empty codes\n",
    "                    self.cur.execute(\"\"\"\n",
    "                        INSERT INTO gen_ed_fulfillments (course_id, gen_ed_code, requirement_group)\n",
    "                        VALUES (%s, %s, %s)\n",
    "                        ON CONFLICT (course_id, gen_ed_code) DO NOTHING\n",
    "                    \"\"\", (course_db_id, gen_ed_code.strip(), group_idx))\n",
    "    \n",
    "    def _save_prerequisites(self, course_db_id: int, requisites: Dict):\n",
    "        \"\"\"Save prerequisites for a course.\"\"\"\n",
    "        # Clear existing prerequisites\n",
    "        self.cur.execute(\"DELETE FROM prerequisites WHERE course_id = %s\", (course_db_id,))\n",
    "        \n",
    "        # Save prerequisites (AND groups)\n",
    "        for group_idx, prereq_group in enumerate(requisites.get('prerequisites', [])):\n",
    "            for prereq_course_code in prereq_group:\n",
    "                prereq_db_id = self.course_id_cache.get(prereq_course_code.strip())\n",
    "                if prereq_db_id:\n",
    "                    self.cur.execute(\"\"\"\n",
    "                        INSERT INTO prerequisites \n",
    "                        (course_id, prereq_group, prereq_course_id, is_corequisite)\n",
    "                        VALUES (%s, %s, %s, %s)\n",
    "                        ON CONFLICT DO NOTHING\n",
    "                    \"\"\", (course_db_id, group_idx, prereq_db_id, False))\n",
    "        \n",
    "        # Save corequisites\n",
    "        for group_idx, coreq_group in enumerate(requisites.get('corequisites', [])):\n",
    "            for coreq_course_code in coreq_group:\n",
    "                coreq_db_id = self.course_id_cache.get(coreq_course_code.strip())\n",
    "                if coreq_db_id:\n",
    "                    self.cur.execute(\"\"\"\n",
    "                        INSERT INTO prerequisites \n",
    "                        (course_id, prereq_group, prereq_course_id, is_corequisite)\n",
    "                        VALUES (%s, %s, %s, %s)\n",
    "                        ON CONFLICT DO NOTHING\n",
    "                    \"\"\", (course_db_id, group_idx + 1000, coreq_db_id, True))\n",
    "    \n",
    "    def _save_grade_requirements(self, course_db_id: int, grade_requirements: Dict):\n",
    "        \"\"\"Save grade requirements for a course.\"\"\"\n",
    "        # Clear existing grade requirements\n",
    "        self.cur.execute(\"DELETE FROM grade_requirements WHERE course_id = %s\", (course_db_id,))\n",
    "        \n",
    "        for req_course_code, min_grade in grade_requirements.items():\n",
    "            # Try different formats\n",
    "            req_course_code = req_course_code.replace(' ', '')\n",
    "            req_db_id = None\n",
    "            for possible_code in [req_course_code, f\"{req_course_code[:4]} {req_course_code[4:]}\"]:\n",
    "                req_db_id = self.course_id_cache.get(possible_code)\n",
    "                if req_db_id:\n",
    "                    break\n",
    "            \n",
    "            if req_db_id:\n",
    "                self.cur.execute(\"\"\"\n",
    "                    INSERT INTO grade_requirements \n",
    "                    (course_id, required_course_id, minimum_grade)\n",
    "                    VALUES (%s, %s, %s)\n",
    "                    ON CONFLICT DO NOTHING\n",
    "                \"\"\", (course_db_id, req_db_id, min_grade))\n",
    "    \n",
    "    def commit(self):\n",
    "        \"\"\"Commit the current transaction.\"\"\"\n",
    "        self.conn.commit()\n",
    "    \n",
    "    def rollback(self):\n",
    "        \"\"\"Rollback the current transaction.\"\"\"\n",
    "        self.conn.rollback()\n",
    "    \n",
    "    def close(self):\n",
    "        \"\"\"Close database connection.\"\"\"\n",
    "        self.cur.close()\n",
    "        self.conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9ac923bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: RequisiteParser class (same as before with minor modifications)\n",
    "class RequisiteParser:\n",
    "    def __init__(self, model=\"gemini-2.5-flash\", delay: float = 0.5):\n",
    "        \"\"\"Initialize the parser with Gemini API.\"\"\"\n",
    "        self.model = genai.GenerativeModel(model)\n",
    "        self.delay = delay\n",
    "        self.api_calls = 0\n",
    "        self.failed_parses = []\n",
    "        self.last_call_time = 0\n",
    "        \n",
    "    def parse_requisites(self, raw: str, course_id: str = None) -> dict:\n",
    "        \"\"\"Parse requisites using Gemini API.\"\"\"\n",
    "        if not raw or not raw.strip():\n",
    "            return {\n",
    "                \"prerequisites\": [],\n",
    "                \"corequisites\": [],\n",
    "                \"grade_requirements\": {},\n",
    "                \"requisites_note\": None\n",
    "            }\n",
    "        \n",
    "        # Rate limiting\n",
    "        current_time = time.time()\n",
    "        time_since_last_call = current_time - self.last_call_time\n",
    "        if time_since_last_call < self.delay:\n",
    "            sleep_time = self.delay - time_since_last_call\n",
    "            time.sleep(sleep_time)\n",
    "        \n",
    "        self.last_call_time = time.time()\n",
    "        self.api_calls += 1\n",
    "        \n",
    "        prompt = f\"\"\"Parse the following course requisite statement and return a JSON object with this exact structure:\n",
    "\n",
    "{{\n",
    "    \"prerequisites\": [\n",
    "        // List of AND-groups, where each group is a list of courses that can be taken as alternatives (OR)\n",
    "        // Example: [[\"COMP 110\"], [\"MATH 231\", \"MATH 241\"]] means COMP 110 AND (MATH 231 OR MATH 241)\n",
    "    ],\n",
    "    \"corequisites\": [\n",
    "        // Same structure as prerequisites but for co-requisites\n",
    "    ],\n",
    "    \"grade_requirements\": {{\n",
    "        // Map of course to required grade\n",
    "        // Example: {{\"COMP 110\": \"C\", \"MATH 231\": \"C+\"}}\n",
    "    }},\n",
    "    \"requisites_note\": // String with any additional requirements like \"permission of instructor\" or null if none\n",
    "}}\n",
    "\n",
    "CRITICAL PARSING RULES:\n",
    "\n",
    "1. AND relationships (all required):\n",
    "   - Separated by \"and\", semicolons (;), or commas in a list\n",
    "   - Example: \"COMP 110 and MATH 231\" ‚Üí [[\"COMP 110\"], [\"MATH 231\"]]\n",
    "   - Example: \"COMP 210; COMP 211; COMP 301\" ‚Üí [[\"COMP 210\"], [\"COMP 211\"], [\"COMP 301\"]]\n",
    "\n",
    "2. OR relationships (choose one):\n",
    "   - Separated by \"or\"\n",
    "   - Example: \"COMP 283 or MATH 381 or STOR 315\" ‚Üí [[\"COMP 283\", \"MATH 381\", \"STOR 315\"]]\n",
    "\n",
    "3. Mixed AND/OR:\n",
    "   - Example: \"MATH 231 or 241; COMP 210, COMP 211, and COMP 301\"\n",
    "   - Parse as: [[\"MATH 231\", \"MATH 241\"], [\"COMP 210\"], [\"COMP 211\"], [\"COMP 301\"]]\n",
    "   - The semicolon separates AND groups, \"or\" creates OR options within a group\n",
    "\n",
    "4. Pre- or corequisites:\n",
    "   - Add the SAME courses to BOTH prerequisites and corequisites arrays\n",
    "   - Example: \"Pre- or corequisites, COMP 283 or MATH 381\"\n",
    "   - Prerequisites: [[\"COMP 283\", \"MATH 381\"]]\n",
    "   - Corequisites: [[\"COMP 283\", \"MATH 381\"]]\n",
    "\n",
    "5. Grade requirements:\n",
    "   - Look for \"grade of X or better\", \"C or better\", etc.\n",
    "   - Apply to ALL courses mentioned in the same clause\n",
    "   - Example: \"COMP 211 and COMP 301; a grade of C or better is required in both\"\n",
    "   - grade_requirements: {{\"COMP 211\": \"C\", \"COMP 301\": \"C\"}}\n",
    "\n",
    "6. Course code format:\n",
    "   - Always format as \"DEPT ###\" with a space (e.g., \"COMP 110\", not \"COMP110\")\n",
    "   - Include letter suffixes if present (e.g., \"BIOL 101L\")\n",
    "\n",
    "7. Special requirements (put in requisites_note):\n",
    "   - \"Permission of the instructor\" ‚Üí Include exact text\n",
    "   - \"May be repeated for credit\" ‚Üí Include this note\n",
    "   - \"Not open to students who have credit for X\" ‚Üí Include full restriction\n",
    "   - \"for students lacking the prerequisite\" ‚Üí Include context\n",
    "   - Any GPA requirements ‚Üí Include exact GPA needed\n",
    "   - Class standing restrictions (e.g., \"Juniors and seniors only\")\n",
    "\n",
    "Common patterns to recognize:\n",
    "- \"Prerequisites, X and Y\" ‚Üí both required\n",
    "- \"Prerequisite, X or Y\" ‚Üí choose one\n",
    "- \"Prerequisites, X; Y or Z\" ‚Üí X is required AND (Y OR Z)\n",
    "- \"one of the following\" ‚Üí all listed courses are OR options\n",
    "- \"all of the following\" ‚Üí all listed courses are AND requirements\n",
    "- \"permission of the instructor for students lacking the prerequisite\" ‚Üí courses are still required, but add note about permission option\n",
    "\n",
    "Example complex requisite:\n",
    "\"Prerequisites, COMP 211 and 301, or COMP 401, 410, and 411; a grade of C or better is required in all prerequisite courses; permission of the instructor for students lacking the prerequisites; may be repeated for credit.\"\n",
    "\n",
    "Should parse to:\n",
    "{{\n",
    "    \"prerequisites\": [[\"COMP 211\", \"COMP 301\"], [\"COMP 401\", \"COMP 410\", \"COMP 411\"]],\n",
    "    \"corequisites\": [],\n",
    "    \"grade_requirements\": {{\"COMP 211\": \"C\", \"COMP 301\": \"C\", \"COMP 401\": \"C\", \"COMP 410\": \"C\", \"COMP 411\": \"C\"}},\n",
    "    \"requisites_note\": \"permission of the instructor for students lacking the prerequisites; may be repeated for credit\"\n",
    "}}\n",
    "\n",
    "Requisite statement to parse:\n",
    "{raw}\n",
    "\n",
    "Return ONLY the JSON object, no explanation or markdown.\"\"\"\n",
    "\n",
    "        try:\n",
    "            response = self.model.generate_content(prompt)\n",
    "            json_text = response.text.strip()\n",
    "            json_text = re.sub(r'^```json\\s*', '', json_text)\n",
    "            json_text = re.sub(r'\\s*```$', '', json_text)\n",
    "            \n",
    "            result = json.loads(json_text)\n",
    "            return self._validate_result(result)\n",
    "            \n",
    "        except Exception as e:\n",
    "            if course_id:\n",
    "                self.failed_parses.append((course_id, str(e)))\n",
    "            return self._fallback_parse(raw)\n",
    "    \n",
    "    def _validate_result(self, result: dict) -> dict:\n",
    "        \"\"\"Validate and clean the parsed result.\"\"\"\n",
    "        validated = {\n",
    "            \"prerequisites\": result.get(\"prerequisites\", []),\n",
    "            \"corequisites\": result.get(\"corequisites\", []),\n",
    "            \"grade_requirements\": result.get(\"grade_requirements\", {}),\n",
    "            \"requisites_note\": result.get(\"requisites_note\", None)\n",
    "        }\n",
    "        \n",
    "        # Ensure prerequisites and corequisites are lists of lists\n",
    "        for key in [\"prerequisites\", \"corequisites\"]:\n",
    "            if not isinstance(validated[key], list):\n",
    "                validated[key] = []\n",
    "            else:\n",
    "                cleaned_list = []\n",
    "                for item in validated[key]:\n",
    "                    if isinstance(item, list):\n",
    "                        cleaned_list.append(item)\n",
    "                    elif isinstance(item, str):\n",
    "                        cleaned_list.append([item])\n",
    "                validated[key] = cleaned_list\n",
    "        \n",
    "        if not isinstance(validated[\"grade_requirements\"], dict):\n",
    "            validated[\"grade_requirements\"] = {}\n",
    "        \n",
    "        return validated\n",
    "    \n",
    "    def _fallback_parse(self, raw: str) -> dict:\n",
    "        \"\"\"Basic fallback parser if API fails.\"\"\"\n",
    "        course_pattern = re.compile(r'\\b[A-Z]{2,5}\\s?\\d{2,3}[A-Z]?\\d?[A-Z]?\\b')\n",
    "        courses = course_pattern.findall(raw)\n",
    "        \n",
    "        normalized_courses = []\n",
    "        for course in courses:\n",
    "            if ' ' not in course:\n",
    "                course = re.sub(r'([A-Z]+)(\\d)', r'\\1 \\2', course)\n",
    "            normalized_courses.append(course)\n",
    "        \n",
    "        prerequisites = [[course] for course in normalized_courses]\n",
    "        \n",
    "        grade_requirements = {}\n",
    "        if 'C or better' in raw or 'grade of C' in raw:\n",
    "            for course in normalized_courses:\n",
    "                grade_requirements[course.replace(' ', '')] = 'C'\n",
    "        \n",
    "        note = None\n",
    "        if 'permission' in raw.lower() or 'instructor' in raw.lower():\n",
    "            note = \"Permission of instructor may be required\"\n",
    "        \n",
    "        return {\n",
    "            \"prerequisites\": prerequisites,\n",
    "            \"corequisites\": [],\n",
    "            \"grade_requirements\": grade_requirements,\n",
    "            \"requisites_note\": note\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f48d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Scraping functions\n",
    "def get_department_links(only=None):\n",
    "    \"\"\"Scrape all department links from the main courses page.\"\"\"\n",
    "    response = requests.get(COURSE_INDEX_URL)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    index_div = soup.find(\"div\", {\"id\": \"atozindex\"})\n",
    "    links = []\n",
    "\n",
    "    for a in index_div.find_all(\"a\", href=True):\n",
    "        dept_code = a['href'].split(\"/\")[-2].upper()\n",
    "        if only is None or dept_code in only:\n",
    "            links.append((dept_code, urljoin(BASE_URL, a['href'])))\n",
    "\n",
    "    return links\n",
    "\n",
    "def parse_course_block(block, parser: RequisiteParser):\n",
    "    \"\"\"Parse a course block from the HTML.\"\"\"\n",
    "    data = {\n",
    "        \"department\": None,\n",
    "        \"course_number\": None,\n",
    "        \"course_name\": None,\n",
    "        \"credits\": None,\n",
    "        \"description\": None,\n",
    "        \"requisites\": {\"prerequisites\": [], \"corequisites\": []},\n",
    "        \"grade_requirements\": {},\n",
    "        \"requisites_note\": None,\n",
    "        \"gen_ed\": None,\n",
    "        \"grading_status\": None,\n",
    "        \"repeat_rules\": None\n",
    "    }\n",
    "\n",
    "    # Header line\n",
    "    header = block.find(\"div\", class_=\"cols noindent\")\n",
    "    if header:\n",
    "        strong_tags = header.find_all(\"strong\")\n",
    "        if len(strong_tags) >= 3:\n",
    "            code = strong_tags[0].text.strip()\n",
    "            if \" \" in code:\n",
    "                data[\"department\"], data[\"course_number\"] = code.split(\" \", 1)\n",
    "                data[\"course_number\"] = data[\"course_number\"].rstrip(\".\")\n",
    "            data[\"course_id\"] = f\"{data['department']} {data['course_number']}\"\n",
    "            data[\"course_name\"] = strong_tags[1].text.strip()\n",
    "            data[\"credits\"] = strong_tags[2].text.strip().replace(\" Credits.\", \"\")\n",
    "\n",
    "    # Description\n",
    "    desc_block = block.find(\"p\", class_=\"courseblockextra\")\n",
    "    if desc_block:\n",
    "        data[\"description\"] = desc_block.text.strip()\n",
    "\n",
    "    # Requisites - using LLM parser\n",
    "    req_span = block.find(\"span\", class_=\"text detail-requisites margin--default\")\n",
    "    if req_span:\n",
    "        course_id = data.get(\"course_id\", \"Unknown\")\n",
    "        req_data = parser.parse_requisites(req_span.text, course_id)\n",
    "        data[\"requisites\"] = {\n",
    "            \"prerequisites\": req_data[\"prerequisites\"],\n",
    "            \"corequisites\": req_data[\"corequisites\"]\n",
    "        }\n",
    "        data[\"grade_requirements\"] = req_data[\"grade_requirements\"]\n",
    "        data[\"requisites_note\"] = req_data[\"requisites_note\"]\n",
    "\n",
    "    # Gen Ed - parse structured format\n",
    "    idea_span = block.find(\"span\", class_=\"text detail-idea_action margin--default\")\n",
    "    if idea_span:\n",
    "        gen_ed_text = idea_span.text.strip().replace(\"IDEAs in Action Gen Ed:\", \"\").strip()\n",
    "        data[\"gen_ed\"] = parse_gen_ed_requirements(gen_ed_text)\n",
    "\n",
    "    # Grading\n",
    "    grading_span = block.find(\"span\", class_=\"text detail-grading_status margin--default\")\n",
    "    if grading_span:\n",
    "        data[\"grading_status\"] = grading_span.text.strip().replace(\"Grading Status: \", \"\").replace(\".\", \"\")\n",
    "    \n",
    "    # Repeat Rules - parse repeat information\n",
    "    repeat_span = block.find(\"span\", class_=\"text detail-repeat_rules margin--default\")\n",
    "    if repeat_span:\n",
    "        data[\"repeat_rules\"] = parse_repeat_rules(repeat_span.text.strip())\n",
    "\n",
    "    return data\n",
    "\n",
    "def parse_repeat_rules(repeat_text: str) -> Dict[str, any]:\n",
    "    \"\"\"\n",
    "    Parse repeat rules text into structured format.\n",
    "    \n",
    "    Example inputs:\n",
    "    - \"Repeat Rules: May be repeated for credit. 9 total credits. 3 total completions.\"\n",
    "    - \"Repeat Rules: May be repeated for credit.\"\n",
    "    \n",
    "    Returns dict with:\n",
    "    - repeatable: bool\n",
    "    - max_credits: int or None\n",
    "    - max_completions: int or None\n",
    "    \"\"\"\n",
    "    if not repeat_text:\n",
    "        return None\n",
    "    \n",
    "    # Remove \"Repeat Rules:\" prefix if present\n",
    "    repeat_text = repeat_text.replace(\"Repeat Rules:\", \"\").strip()\n",
    "    \n",
    "    result = {\n",
    "        \"repeatable\": False,\n",
    "        \"max_credits\": None,\n",
    "        \"max_completions\": None,\n",
    "        \"raw_text\": repeat_text\n",
    "    }\n",
    "    \n",
    "    # Check if repeatable\n",
    "    if \"may be repeated\" in repeat_text.lower():\n",
    "        result[\"repeatable\"] = True\n",
    "        \n",
    "        # Extract max credits\n",
    "        credits_match = re.search(r'(\\d+)\\s*total\\s*credits?', repeat_text, re.IGNORECASE)\n",
    "        if credits_match:\n",
    "            result[\"max_credits\"] = int(credits_match.group(1))\n",
    "        \n",
    "        # Extract max completions\n",
    "        completions_match = re.search(r'(\\d+)\\s*total\\s*completions?', repeat_text, re.IGNORECASE)\n",
    "        if completions_match:\n",
    "            result[\"max_completions\"] = int(completions_match.group(1))\n",
    "    \n",
    "    return result\n",
    "\n",
    "def parse_gen_ed_requirements(gen_ed_text: str):\n",
    "    \"\"\"\n",
    "    Parse gen ed requirements with AND/OR logic.\n",
    "\n",
    "    Examples:\n",
    "    - \"FY-SEMINAR, FC-PAST or FC-POWER.\" -> [[\"FY-SEMINAR\"], [\"FC-PAST\", \"FC-POWER\"]]\n",
    "    - \"FY-SEMINAR.\" -> [[\"FY-SEMINAR\"]]\n",
    "    - \"FC-PAST or FC-POWER.\" -> [[\"FC-PAST\", \"FC-POWER\"]]\n",
    "\n",
    "    Returns a list of lists where:\n",
    "    - Outer list items are AND'ed (all required)\n",
    "    - Inner list items are OR'ed (choose one)\n",
    "    \"\"\"\n",
    "    if not gen_ed_text:\n",
    "        return []\n",
    "\n",
    "    gen_ed_text = gen_ed_text.replace(\"(only designated sections)\", \"\")\n",
    "    # Split by commas for AND groups\n",
    "    and_groups = [group.strip() for group in gen_ed_text.split(',')]\n",
    "\n",
    "    result = []\n",
    "    for group in and_groups:\n",
    "        # Remove any periods\n",
    "        group = group.replace('.', '')\n",
    "\n",
    "        # Check if this group has OR options\n",
    "        if re.search(r'\\bor\\b', group, flags=re.IGNORECASE):\n",
    "            # Split by 'or' for OR options\n",
    "            or_options = [\n",
    "                opt.strip().replace('.', '')\n",
    "                for opt in re.split(r'\\s+or\\s+', group, flags=re.IGNORECASE)\n",
    "            ]\n",
    "            result.append(or_options)\n",
    "        else:\n",
    "            result.append([group])\n",
    "\n",
    "    return result\n",
    "\n",
    "def parse_department(url, parser: RequisiteParser, dept_code: str, db_manager: DatabaseManager, mode: str = 'database'):\n",
    "    \"\"\"Parse all courses from a department page.\"\"\"\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    course_blocks = soup.find_all(\"div\", class_=\"courseblock\")\n",
    "    \n",
    "    total_courses = len(course_blocks)\n",
    "    print(f\"   Found {total_courses} courses to parse\")\n",
    "    \n",
    "    courses = []\n",
    "    saved_count = 0\n",
    "    \n",
    "    for i, cb in enumerate(course_blocks, 1):\n",
    "        # Extract course ID for progress display\n",
    "        header = cb.find(\"div\", class_=\"cols noindent\")\n",
    "        course_id = \"Unknown\"\n",
    "        if header:\n",
    "            strong_tags = header.find_all(\"strong\")\n",
    "            if strong_tags:\n",
    "                course_id = strong_tags[0].text.strip()\n",
    "        \n",
    "        print(f\"   Processing {course_id} ({i}/{total_courses})...\", end='\\r')\n",
    "        \n",
    "        course_data = parse_course_block(cb, parser)\n",
    "        \n",
    "        # Save to database if in database mode\n",
    "        if mode in ['database', 'both'] and db_manager:\n",
    "            try:\n",
    "                db_manager.save_course(course_data)\n",
    "                saved_count += 1\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Failed to save {course_id}: {e}\")\n",
    "        \n",
    "        # Collect for JSON if needed\n",
    "        if mode in ['json', 'both']:\n",
    "            courses.append(course_data)\n",
    "    \n",
    "    print(f\"   ‚úì Completed all {total_courses} courses in {dept_code} (saved {saved_count} to database)     \")\n",
    "    return courses\n",
    "\n",
    "def scrape_all_courses(parser: RequisiteParser, db_manager: Optional[DatabaseManager] = None, \n",
    "                      only=None, mode='database', dry_run=False, update_existing=True):\n",
    "    \"\"\"\n",
    "    Scrape all courses with flexible output options.\n",
    "    \n",
    "    Args:\n",
    "        parser: RequisiteParser instance\n",
    "        db_manager: DatabaseManager instance (required for database mode)\n",
    "        only: Set of department codes to scrape (None for all)\n",
    "        mode: 'database', 'json', or 'both'\n",
    "        dry_run: If True, don't actually save anything\n",
    "        update_existing: If True, update existing courses; if False, skip them\n",
    "    \"\"\"\n",
    "    department_links = get_department_links(only=only)\n",
    "    all_courses = {}\n",
    "    \n",
    "    print(f\"\\nüéØ Starting scrape of {len(department_links)} departments\")\n",
    "    print(f\"   Mode: {mode}\")\n",
    "    print(f\"   Dry run: {dry_run}\")\n",
    "    print(f\"   Update existing: {update_existing}\\n\")\n",
    "    \n",
    "    overall_start_time = time.time()\n",
    "\n",
    "    for dept_idx, (dept_code, url) in enumerate(department_links, 1):\n",
    "        try:\n",
    "            print(f\"üìö [{dept_idx}/{len(department_links)}] Scraping {dept_code}...\")\n",
    "            dept_start_time = time.time()\n",
    "            \n",
    "            # Begin transaction for this department\n",
    "            if db_manager and not dry_run:\n",
    "                db_manager.conn.commit()  # Commit any pending changes\n",
    "            \n",
    "            courses = parse_department(url, parser, dept_code, db_manager if not dry_run else None, mode)\n",
    "            \n",
    "            if mode in ['json', 'both']:\n",
    "                all_courses[dept_code] = courses\n",
    "            \n",
    "            # Commit department transaction\n",
    "            if db_manager and not dry_run and mode in ['database', 'both']:\n",
    "                db_manager.commit()\n",
    "            \n",
    "            dept_elapsed = time.time() - dept_start_time\n",
    "            print(f\"‚úÖ Successfully scraped {dept_code} in {dept_elapsed/60:.1f} minutes\\n\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error scraping {dept_code}: {e}\\n\")\n",
    "            if db_manager and not dry_run:\n",
    "                db_manager.rollback()\n",
    "    \n",
    "    overall_elapsed = time.time() - overall_start_time\n",
    "    print(f\"‚è±Ô∏è  Total scraping time: {overall_elapsed/60:.1f} minutes\")\n",
    "    \n",
    "    return all_courses\n",
    "\n",
    "def save_to_json(data, filename=\"unc_courses.json\"):\n",
    "    \"\"\"Save course data to JSON file.\"\"\"\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, indent=2, ensure_ascii=False)\n",
    "    print(f\"\\nüíæ Saved to {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e9fb77b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-22 23:55:13,622 - INFO - Loaded 152 departments and 10212 courses into cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéØ Starting scrape of 1 departments\n",
      "   Mode: database\n",
      "   Dry run: False\n",
      "   Update existing: True\n",
      "\n",
      "üìö [1/1] Scraping AAAD...\n",
      "   Found 123 courses to parse\n",
      "   Processing AAAD 50. (1/123)...\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[48]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Option 1: Scrape sample departments\u001b[39;00m\n\u001b[32m     12\u001b[39m sample_departments = {\u001b[33m\"\u001b[39m\u001b[33mAAAD\u001b[39m\u001b[33m\"\u001b[39m}\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m courses = \u001b[43mscrape_all_courses\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparser\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdb_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43monly\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_departments\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mMODE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdry_run\u001b[49m\u001b[43m=\u001b[49m\u001b[43mDRY_RUN\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43mupdate_existing\u001b[49m\u001b[43m=\u001b[49m\u001b[43mUPDATE_EXISTING\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m MODE \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m'\u001b[39m\u001b[33mjson\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mboth\u001b[39m\u001b[33m'\u001b[39m] \u001b[38;5;129;01mand\u001b[39;00m courses:\n\u001b[32m     22\u001b[39m     save_to_json(courses, \u001b[33m\"\u001b[39m\u001b[33munc_courses_sample.json\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[46]\u001b[39m\u001b[32m, line 232\u001b[39m, in \u001b[36mscrape_all_courses\u001b[39m\u001b[34m(parser, db_manager, only, mode, dry_run, update_existing)\u001b[39m\n\u001b[32m    229\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m db_manager \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m dry_run:\n\u001b[32m    230\u001b[39m     db_manager.conn.commit()  \u001b[38;5;66;03m# Commit any pending changes\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m232\u001b[39m courses = \u001b[43mparse_department\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparser\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdept_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdb_manager\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdry_run\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m'\u001b[39m\u001b[33mjson\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mboth\u001b[39m\u001b[33m'\u001b[39m]:\n\u001b[32m    235\u001b[39m     all_courses[dept_code] = courses\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[46]\u001b[39m\u001b[32m, line 188\u001b[39m, in \u001b[36mparse_department\u001b[39m\u001b[34m(url, parser, dept_code, db_manager, mode)\u001b[39m\n\u001b[32m    186\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m'\u001b[39m\u001b[33mdatabase\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mboth\u001b[39m\u001b[33m'\u001b[39m] \u001b[38;5;129;01mand\u001b[39;00m db_manager:\n\u001b[32m    187\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m188\u001b[39m         \u001b[43mdb_manager\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave_course\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcourse_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    189\u001b[39m         saved_count += \u001b[32m1\u001b[39m\n\u001b[32m    190\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[37]\u001b[39m\u001b[32m, line 77\u001b[39m, in \u001b[36mDatabaseManager.save_course\u001b[39m\u001b[34m(self, course_data)\u001b[39m\n\u001b[32m     74\u001b[39m     max_repeat_completions = repeat_rules.get(\u001b[33m'\u001b[39m\u001b[33mmax_completions\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     76\u001b[39m \u001b[38;5;66;03m# Insert or update course\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcur\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\"\"\u001b[39;49m\n\u001b[32m     78\u001b[39m \u001b[33;43m    INSERT INTO courses \u001b[39;49m\n\u001b[32m     79\u001b[39m \u001b[33;43m    (course_id, department_id, course_number, name, description, \u001b[39;49m\n\u001b[32m     80\u001b[39m \u001b[33;43m     credits, grading_status, requisites_note, repeatable, \u001b[39;49m\n\u001b[32m     81\u001b[39m \u001b[33;43m     max_repeat_credits, max_repeat_completions)\u001b[39;49m\n\u001b[32m     82\u001b[39m \u001b[33;43m    VALUES (\u001b[39;49m\u001b[38;5;132;43;01m%s\u001b[39;49;00m\u001b[33;43m, \u001b[39;49m\u001b[38;5;132;43;01m%s\u001b[39;49;00m\u001b[33;43m, \u001b[39;49m\u001b[38;5;132;43;01m%s\u001b[39;49;00m\u001b[33;43m, \u001b[39;49m\u001b[38;5;132;43;01m%s\u001b[39;49;00m\u001b[33;43m, \u001b[39;49m\u001b[38;5;132;43;01m%s\u001b[39;49;00m\u001b[33;43m, \u001b[39;49m\u001b[38;5;132;43;01m%s\u001b[39;49;00m\u001b[33;43m, \u001b[39;49m\u001b[38;5;132;43;01m%s\u001b[39;49;00m\u001b[33;43m, \u001b[39;49m\u001b[38;5;132;43;01m%s\u001b[39;49;00m\u001b[33;43m, \u001b[39;49m\u001b[38;5;132;43;01m%s\u001b[39;49;00m\u001b[33;43m, \u001b[39;49m\u001b[38;5;132;43;01m%s\u001b[39;49;00m\u001b[33;43m, \u001b[39;49m\u001b[38;5;132;43;01m%s\u001b[39;49;00m\u001b[33;43m)\u001b[39;49m\n\u001b[32m     83\u001b[39m \u001b[33;43m    ON CONFLICT (course_id) DO UPDATE SET\u001b[39;49m\n\u001b[32m     84\u001b[39m \u001b[33;43m        name = EXCLUDED.name,\u001b[39;49m\n\u001b[32m     85\u001b[39m \u001b[33;43m        description = EXCLUDED.description,\u001b[39;49m\n\u001b[32m     86\u001b[39m \u001b[33;43m        credits = EXCLUDED.credits,\u001b[39;49m\n\u001b[32m     87\u001b[39m \u001b[33;43m        grading_status = EXCLUDED.grading_status,\u001b[39;49m\n\u001b[32m     88\u001b[39m \u001b[33;43m        requisites_note = EXCLUDED.requisites_note,\u001b[39;49m\n\u001b[32m     89\u001b[39m \u001b[33;43m        repeatable = EXCLUDED.repeatable,\u001b[39;49m\n\u001b[32m     90\u001b[39m \u001b[33;43m        max_repeat_credits = EXCLUDED.max_repeat_credits,\u001b[39;49m\n\u001b[32m     91\u001b[39m \u001b[33;43m        max_repeat_completions = EXCLUDED.max_repeat_completions,\u001b[39;49m\n\u001b[32m     92\u001b[39m \u001b[33;43m        updated_at = NOW()\u001b[39;49m\n\u001b[32m     93\u001b[39m \u001b[33;43m    RETURNING id\u001b[39;49m\n\u001b[32m     94\u001b[39m \u001b[33;43m\u001b[39;49m\u001b[33;43m\"\"\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     95\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcourse_data\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcourse_id\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     96\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdept_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     97\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcourse_data\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcourse_number\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     98\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcourse_data\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcourse_name\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     99\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcourse_data\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdescription\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    100\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcourse_data\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcredits\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    101\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcourse_data\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mgrading_status\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    102\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcourse_data\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mrequisites_note\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    103\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrepeatable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    104\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_repeat_credits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    105\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_repeat_completions\u001b[49m\n\u001b[32m    106\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    108\u001b[39m course_db_id = \u001b[38;5;28mself\u001b[39m.cur.fetchone()[\u001b[33m'\u001b[39m\u001b[33mid\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m    109\u001b[39m \u001b[38;5;28mself\u001b[39m.course_id_cache[course_data[\u001b[33m'\u001b[39m\u001b[33mcourse_id\u001b[39m\u001b[33m'\u001b[39m]] = course_db_id\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\malac\\anaconda3\\envs\\pathfinder\\Lib\\site-packages\\psycopg2\\extras.py:236\u001b[39m, in \u001b[36mRealDictCursor.execute\u001b[39m\u001b[34m(self, query, vars)\u001b[39m\n\u001b[32m    234\u001b[39m \u001b[38;5;28mself\u001b[39m.column_mapping = []\n\u001b[32m    235\u001b[39m \u001b[38;5;28mself\u001b[39m._query_executed = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m236\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mvars\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\malac\\anaconda3\\envs\\pathfinder\\Lib\\encodings\\utf_8.py:15\u001b[39m, in \u001b[36mdecode\u001b[39m\u001b[34m(input, errors)\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m### Codec APIs\u001b[39;00m\n\u001b[32m     13\u001b[39m encode = codecs.utf_8_encode\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecode\u001b[39m(\u001b[38;5;28minput\u001b[39m, errors=\u001b[33m'\u001b[39m\u001b[33mstrict\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m     16\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m codecs.utf_8_decode(\u001b[38;5;28minput\u001b[39m, errors, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mIncrementalEncoder\u001b[39;00m(codecs.IncrementalEncoder):\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Cell 6: Main execution\n",
    "# Initialize components\n",
    "parser = RequisiteParser(model=\"gemini-2.5-flash\", delay=0.5)\n",
    "db_manager = DatabaseManager(DATABASE_URL)\n",
    "\n",
    "# Configuration options\n",
    "MODE = 'database'  # 'database', 'json', or 'both'\n",
    "DRY_RUN = False    # Set to True to test without saving\n",
    "UPDATE_EXISTING = True  # Set to False to skip existing courses\n",
    "\n",
    "# Option 1: Scrape sample departments\n",
    "sample_departments = {\"AAAD\"}\n",
    "courses = scrape_all_courses(\n",
    "    parser, \n",
    "    db_manager,\n",
    "    only=sample_departments,\n",
    "    mode=MODE,\n",
    "    dry_run=DRY_RUN,\n",
    "    update_existing=UPDATE_EXISTING\n",
    ")\n",
    "if MODE in ['json', 'both'] and courses:\n",
    "    save_to_json(courses, \"unc_courses_sample.json\")\n",
    "\n",
    "# Option 2: Scrape all departments (uncomment to use)\n",
    "# courses = scrape_all_courses(parser, db_manager, mode=MODE)\n",
    "# if MODE in ['json', 'both'] and courses:\n",
    "#     save_to_json(courses, \"unc_courses.json\")\n",
    "\n",
    "# Print statistics\n",
    "print(f\"\\nüìä Statistics:\")\n",
    "print(f\"   Total API calls: {parser.api_calls}\")\n",
    "print(f\"   Failed parses: {len(parser.failed_parses)}\")\n",
    "if parser.failed_parses:\n",
    "    print(\"\\n‚ö†Ô∏è  Failed to parse requisites for:\")\n",
    "    for course_id, error in parser.failed_parses[:5]:\n",
    "        print(f\"   - {course_id}: {error[:50]}...\")\n",
    "    if len(parser.failed_parses) > 5:\n",
    "        print(f\"   ... and {len(parser.failed_parses) - 5} more\")\n",
    "\n",
    "# Close database connection\n",
    "db_manager.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28faaee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Database Contents:\n",
      "   Total courses: 10212\n",
      "   Courses with prerequisites: 2405\n",
      "\n",
      "üìö Sample courses:\n",
      "   COMP 110: Introduction to Programming.\n",
      "   COMP 211: Systems Fundamentals.\n",
      "      Prerequisites: 1 groups\n",
      "   BIOL 101: Principles of Biology.\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Database verification\n",
    "def verify_scraping_results():\n",
    "    \"\"\"Verify what was scraped into the database.\"\"\"\n",
    "    from db_queries import CourseDatabase\n",
    "    \n",
    "    with CourseDatabase() as db:\n",
    "        stats = db.get_database_stats()\n",
    "        print(\"\\nüîç Database Contents:\")\n",
    "        print(f\"   Total courses: {stats['total_courses']}\")\n",
    "        print(f\"   Courses with prerequisites: {stats['courses_with_prereqs']}\")\n",
    "        \n",
    "        # Show sample courses\n",
    "        print(\"\\nüìö Sample courses:\")\n",
    "        sample_courses = [\"COMP 110\", \"COMP 211\", \"BIOL 101\"]\n",
    "        for course_id in sample_courses:\n",
    "            course = db.get_course(course_id)\n",
    "            if course:\n",
    "                prereqs = db.get_course_prerequisites(course_id)\n",
    "                print(f\"   {course_id}: {course['name']}\")\n",
    "                if prereqs['prerequisites']:\n",
    "                    print(f\"      Prerequisites: {len(prereqs['prerequisites'])} groups\")\n",
    "\n",
    "# Run verification\n",
    "verify_scraping_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e465a4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Analyzing 152 departments...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning departments: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 152/152 [01:12<00:00,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Requisite Analysis Complete!\n",
      "\n",
      "Total courses across all departments: 10212\n",
      "Courses with requisites: 2759\n",
      "Courses without requisites: 7453\n",
      "Percentage with requisites: 27.0%\n",
      "\n",
      "üí° You will need 2759 API calls\n",
      "‚è±Ô∏è  Estimated time at 2.1s/call: 96.6 minutes\n",
      "\n",
      "üìà Top 10 departments by requisite count:\n",
      "   BIOL: 167/264 courses (63%)\n",
      "   PSYC: 101/183 courses (55%)\n",
      "   NURS: 91/169 courses (54%)\n",
      "   ECON: 81/145 courses (56%)\n",
      "   COMP: 79/109 courses (72%)\n",
      "   PHCY: 75/112 courses (67%)\n",
      "   CHEM: 74/112 courses (66%)\n",
      "   SPAN: 71/119 courses (60%)\n",
      "   MATH: 70/110 courses (64%)\n",
      "   COMM: 69/213 courses (32%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell to count non-empty requisites across all departments\n",
    "def count_requisites(only=None):\n",
    "    \"\"\"Count how many courses have non-empty requisites across departments.\"\"\"\n",
    "    department_links = get_department_links(only=only)\n",
    "    \n",
    "    total_courses = 0\n",
    "    courses_with_requisites = 0\n",
    "    dept_stats = {}\n",
    "    \n",
    "    print(f\"üîç Analyzing {len(department_links)} departments...\\n\")\n",
    "    \n",
    "    for dept_code, url in tqdm(department_links, desc=\"Scanning departments\"):\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        course_blocks = soup.find_all(\"div\", class_=\"courseblock\")\n",
    "        \n",
    "        dept_total = len(course_blocks)\n",
    "        dept_with_reqs = 0\n",
    "        \n",
    "        for block in course_blocks:\n",
    "            req_span = block.find(\"span\", class_=\"text detail-requisites margin--default\")\n",
    "            if req_span and req_span.text.strip() and req_span.text.strip() != \"Requisites:\":\n",
    "                dept_with_reqs += 1\n",
    "        \n",
    "        dept_stats[dept_code] = {\n",
    "            \"total\": dept_total,\n",
    "            \"with_requisites\": dept_with_reqs,\n",
    "            \"percentage\": (dept_with_reqs / dept_total * 100) if dept_total > 0 else 0\n",
    "        }\n",
    "        \n",
    "        total_courses += dept_total\n",
    "        courses_with_requisites += dept_with_reqs\n",
    "    \n",
    "    # Print summary\n",
    "    print(f\"\\nüìä Requisite Analysis Complete!\\n\")\n",
    "    print(f\"Total courses across all departments: {total_courses}\")\n",
    "    print(f\"Courses with requisites: {courses_with_requisites}\")\n",
    "    print(f\"Courses without requisites: {total_courses - courses_with_requisites}\")\n",
    "    print(f\"Percentage with requisites: {courses_with_requisites/total_courses*100:.1f}%\")\n",
    "    print(f\"\\nüí° You will need {courses_with_requisites} API calls\")\n",
    "    print(f\"‚è±Ô∏è  Estimated time at 2.1s/call: {courses_with_requisites * 2.1 / 60:.1f} minutes\")\n",
    "    \n",
    "    # Show top departments by requisite count\n",
    "    print(f\"\\nüìà Top 10 departments by requisite count:\")\n",
    "    sorted_depts = sorted(dept_stats.items(), key=lambda x: x[1]['with_requisites'], reverse=True)[:10]\n",
    "    for dept, stats in sorted_depts:\n",
    "        print(f\"   {dept}: {stats['with_requisites']}/{stats['total']} courses ({stats['percentage']:.0f}%)\")\n",
    "    \n",
    "    return dept_stats\n",
    "\n",
    "# Run the analysis\n",
    "# For all departments:\n",
    "dept_stats = count_requisites()\n",
    "\n",
    "# Or for specific departments:\n",
    "# dept_stats = count_requisites(only={\"COMP\", \"MATH\", \"BIOL\", \"CHEM\", \"PHYS\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pathfinder",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
