{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c3a9af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\malac\\anaconda3\\envs\\pathfinder\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Import and setup\n",
    "import re\n",
    "import json\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "from tqdm import tqdm\n",
    "import google.generativeai as genai\n",
    "import time\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import psycopg2\n",
    "from psycopg2.extras import RealDictCursor\n",
    "import logging\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Optional\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344947c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Configure API and Database\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "DATABASE_URL = os.getenv(\"DATABASE_URL\")\n",
    "\n",
    "if not GEMINI_API_KEY:\n",
    "    raise ValueError(\"GEMINI_API_KEY not found in .env file\")\n",
    "\n",
    "if not DATABASE_URL:\n",
    "    raise ValueError(\"DATABASE_URL not found in .env file\")\n",
    "\n",
    "genai.configure(api_key=GEMINI_API_KEY)\n",
    "\n",
    "BASE_URL = \"https://catalog.unc.edu\"\n",
    "COURSE_INDEX_URL = f\"{BASE_URL}/courses/#text\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c1151b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Database Manager class\n",
    "class DatabaseManager:\n",
    "    def __init__(self, db_url: str):\n",
    "        \"\"\"Initialize database connection and caches.\"\"\"\n",
    "        # Parse the URL to add gssencmode parameter\n",
    "        from urllib.parse import urlparse\n",
    "        url = urlparse(db_url)\n",
    "        \n",
    "        conn_params = {\n",
    "            \"host\": url.hostname,\n",
    "            \"port\": url.port,\n",
    "            \"database\": url.path[1:],\n",
    "            \"user\": url.username,\n",
    "            \"password\": url.password,\n",
    "            \"sslmode\": \"require\",\n",
    "            \"gssencmode\": \"disable\"\n",
    "        }\n",
    "        \n",
    "        self.conn = psycopg2.connect(**conn_params)\n",
    "        self.conn.autocommit = False\n",
    "        self.cur = self.conn.cursor(cursor_factory=RealDictCursor)\n",
    "        \n",
    "        # Cache for lookups\n",
    "        self.department_cache = {}\n",
    "        self.course_id_cache = {}\n",
    "        \n",
    "        # Load existing data into cache\n",
    "        self._load_cache()\n",
    "    \n",
    "    def _load_cache(self):\n",
    "        \"\"\"Load existing departments and courses into cache.\"\"\"\n",
    "        # Load departments\n",
    "        self.cur.execute(\"SELECT id, code FROM departments\")\n",
    "        for row in self.cur.fetchall():\n",
    "            self.department_cache[row['code']] = row['id']\n",
    "        \n",
    "        # Load course IDs\n",
    "        self.cur.execute(\"SELECT id, course_id FROM courses\")\n",
    "        for row in self.cur.fetchall():\n",
    "            self.course_id_cache[row['course_id']] = row['id']\n",
    "        \n",
    "        logger.info(f\"Loaded {len(self.department_cache)} departments and {len(self.course_id_cache)} courses into cache\")\n",
    "    \n",
    "    def get_or_create_department(self, dept_code: str) -> int:\n",
    "        \"\"\"Get or create a department, returning its ID.\"\"\"\n",
    "        if dept_code in self.department_cache:\n",
    "            return self.department_cache[dept_code]\n",
    "        \n",
    "        self.cur.execute(\"\"\"\n",
    "            INSERT INTO departments (code) \n",
    "            VALUES (%s) \n",
    "            ON CONFLICT (code) DO UPDATE SET code = EXCLUDED.code\n",
    "            RETURNING id\n",
    "        \"\"\", (dept_code,))\n",
    "        \n",
    "        dept_id = self.cur.fetchone()['id']\n",
    "        self.department_cache[dept_code] = dept_id\n",
    "        return dept_id\n",
    "    \n",
    "    def save_course(self, course_data: dict, update_existing: bool = True):\n",
    "    \"\"\"Save a course to the database.\"\"\"\n",
    "    try:\n",
    "        # Check if course exists\n",
    "        existing_course = self.course_cache.get(course_data.get(\"course_id\"))\n",
    "        \n",
    "        if existing_course and not update_existing:\n",
    "            return\n",
    "        \n",
    "        conn = psycopg2.connect(self.db_url)\n",
    "        cur = conn.cursor()\n",
    "        \n",
    "        # Prepare repeat_rules JSON if present\n",
    "        repeat_rules_json = None\n",
    "        if course_data.get(\"repeat_rules\"):\n",
    "            repeat_rules_json = json.dumps(course_data[\"repeat_rules\"])\n",
    "        \n",
    "        if existing_course:\n",
    "            # Update existing course\n",
    "            update_query = \"\"\"\n",
    "                UPDATE courses \n",
    "                SET name = %s,\n",
    "                    credits = %s,\n",
    "                    description = %s,\n",
    "                    gen_ed_requirements = %s,\n",
    "                    grading_status = %s,\n",
    "                    repeat_rules = %s,\n",
    "                    updated_at = CURRENT_TIMESTAMP\n",
    "                WHERE course_id = %s\n",
    "            \"\"\"\n",
    "            cur.execute(update_query, (\n",
    "                course_data.get(\"course_name\"),\n",
    "                course_data.get(\"credits\"),\n",
    "                course_data.get(\"description\"),\n",
    "                json.dumps(course_data.get(\"gen_ed\", [])) if course_data.get(\"gen_ed\") else None,\n",
    "                course_data.get(\"grading_status\"),\n",
    "                repeat_rules_json,\n",
    "                course_data.get(\"course_id\")\n",
    "            ))\n",
    "        else:\n",
    "            # Insert new course\n",
    "            insert_query = \"\"\"\n",
    "                INSERT INTO courses (course_id, department, course_number, name, credits, \n",
    "                                   description, gen_ed_requirements, grading_status, repeat_rules)\n",
    "                VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "            \"\"\"\n",
    "            cur.execute(insert_query, (\n",
    "                course_data.get(\"course_id\"),\n",
    "                course_data.get(\"department\"),\n",
    "                course_data.get(\"course_number\"),\n",
    "                course_data.get(\"course_name\"),\n",
    "                course_data.get(\"credits\"),\n",
    "                course_data.get(\"description\"),\n",
    "                json.dumps(course_data.get(\"gen_ed\", [])) if course_data.get(\"gen_ed\") else None,\n",
    "                course_data.get(\"grading_status\"),\n",
    "                repeat_rules_json\n",
    "            ))\n",
    "        \n",
    "        # Save prerequisites\n",
    "        if course_data.get(\"requisites\", {}).get(\"prerequisites\"):\n",
    "            self._save_prerequisites(\n",
    "                cur,\n",
    "                course_data.get(\"course_id\"),\n",
    "                course_data[\"requisites\"][\"prerequisites\"],\n",
    "                course_data.get(\"grade_requirements\", {}),\n",
    "                course_data.get(\"requisites_note\")\n",
    "            )\n",
    "        \n",
    "        # Save corequisites\n",
    "        if course_data.get(\"requisites\", {}).get(\"corequisites\"):\n",
    "            self._save_corequisites(\n",
    "                cur,\n",
    "                course_data.get(\"course_id\"),\n",
    "                course_data[\"requisites\"][\"corequisites\"]\n",
    "            )\n",
    "        \n",
    "        conn.commit()\n",
    "        cur.close()\n",
    "        conn.close()\n",
    "        \n",
    "        # Update cache\n",
    "        self.course_cache[course_data.get(\"course_id\")] = course_data.get(\"course_id\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error saving course {course_data.get('course_id')}: {e}\")\n",
    "        raise\n",
    "    \n",
    "    def _save_gen_ed_fulfillments(self, course_db_id: int, gen_ed_groups: List[List[str]]):\n",
    "        \"\"\"Save gen ed fulfillments to normalized table.\"\"\"\n",
    "        # Clear existing fulfillments\n",
    "        self.cur.execute(\"DELETE FROM gen_ed_fulfillments WHERE course_id = %s\", (course_db_id,))\n",
    "        \n",
    "        # Save new fulfillments\n",
    "        for group_idx, group in enumerate(gen_ed_groups):\n",
    "            for gen_ed_code in group:\n",
    "                if gen_ed_code:  # Skip empty codes\n",
    "                    self.cur.execute(\"\"\"\n",
    "                        INSERT INTO gen_ed_fulfillments (course_id, gen_ed_code, requirement_group)\n",
    "                        VALUES (%s, %s, %s)\n",
    "                        ON CONFLICT (course_id, gen_ed_code) DO NOTHING\n",
    "                    \"\"\", (course_db_id, gen_ed_code.strip(), group_idx))\n",
    "    \n",
    "    def _save_prerequisites(self, course_db_id: int, requisites: Dict):\n",
    "        \"\"\"Save prerequisites for a course.\"\"\"\n",
    "        # Clear existing prerequisites\n",
    "        self.cur.execute(\"DELETE FROM prerequisites WHERE course_id = %s\", (course_db_id,))\n",
    "        \n",
    "        # Save prerequisites (AND groups)\n",
    "        for group_idx, prereq_group in enumerate(requisites.get('prerequisites', [])):\n",
    "            for prereq_course_code in prereq_group:\n",
    "                prereq_db_id = self.course_id_cache.get(prereq_course_code.strip())\n",
    "                if prereq_db_id:\n",
    "                    self.cur.execute(\"\"\"\n",
    "                        INSERT INTO prerequisites \n",
    "                        (course_id, prereq_group, prereq_course_id, is_corequisite)\n",
    "                        VALUES (%s, %s, %s, %s)\n",
    "                        ON CONFLICT DO NOTHING\n",
    "                    \"\"\", (course_db_id, group_idx, prereq_db_id, False))\n",
    "        \n",
    "        # Save corequisites\n",
    "        for group_idx, coreq_group in enumerate(requisites.get('corequisites', [])):\n",
    "            for coreq_course_code in coreq_group:\n",
    "                coreq_db_id = self.course_id_cache.get(coreq_course_code.strip())\n",
    "                if coreq_db_id:\n",
    "                    self.cur.execute(\"\"\"\n",
    "                        INSERT INTO prerequisites \n",
    "                        (course_id, prereq_group, prereq_course_id, is_corequisite)\n",
    "                        VALUES (%s, %s, %s, %s)\n",
    "                        ON CONFLICT DO NOTHING\n",
    "                    \"\"\", (course_db_id, group_idx + 1000, coreq_db_id, True))\n",
    "    \n",
    "    def _save_grade_requirements(self, course_db_id: int, grade_requirements: Dict):\n",
    "        \"\"\"Save grade requirements for a course.\"\"\"\n",
    "        # Clear existing grade requirements\n",
    "        self.cur.execute(\"DELETE FROM grade_requirements WHERE course_id = %s\", (course_db_id,))\n",
    "        \n",
    "        for req_course_code, min_grade in grade_requirements.items():\n",
    "            # Try different formats\n",
    "            req_course_code = req_course_code.replace(' ', '')\n",
    "            req_db_id = None\n",
    "            for possible_code in [req_course_code, f\"{req_course_code[:4]} {req_course_code[4:]}\"]:\n",
    "                req_db_id = self.course_id_cache.get(possible_code)\n",
    "                if req_db_id:\n",
    "                    break\n",
    "            \n",
    "            if req_db_id:\n",
    "                self.cur.execute(\"\"\"\n",
    "                    INSERT INTO grade_requirements \n",
    "                    (course_id, required_course_id, minimum_grade)\n",
    "                    VALUES (%s, %s, %s)\n",
    "                    ON CONFLICT DO NOTHING\n",
    "                \"\"\", (course_db_id, req_db_id, min_grade))\n",
    "    \n",
    "    def commit(self):\n",
    "        \"\"\"Commit the current transaction.\"\"\"\n",
    "        self.conn.commit()\n",
    "    \n",
    "    def rollback(self):\n",
    "        \"\"\"Rollback the current transaction.\"\"\"\n",
    "        self.conn.rollback()\n",
    "    \n",
    "    def close(self):\n",
    "        \"\"\"Close database connection.\"\"\"\n",
    "        self.cur.close()\n",
    "        self.conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac923bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: RequisiteParser class\n",
    "class RequisiteParser:\n",
    "    def __init__(self, model=\"gemini-1.5-flash\", delay: float = 2.1):\n",
    "        \"\"\"Initialize the parser with Gemini API.\"\"\"\n",
    "        self.model = genai.GenerativeModel(model)\n",
    "        self.delay = delay\n",
    "        self.api_calls = 0\n",
    "        self.failed_parses = []\n",
    "        self.last_call_time = 0\n",
    "        \n",
    "    def parse_requisites(self, raw: str, course_id: str = None) -> dict:\n",
    "        \"\"\"Parse requisites using Gemini API.\"\"\"\n",
    "        if not raw or not raw.strip():\n",
    "            return {\n",
    "                \"prerequisites\": [],\n",
    "                \"corequisites\": [],\n",
    "                \"grade_requirements\": {},\n",
    "                \"requisites_note\": None\n",
    "            }\n",
    "        \n",
    "        # Rate limiting\n",
    "        current_time = time.time()\n",
    "        time_since_last_call = current_time - self.last_call_time\n",
    "        if time_since_last_call < self.delay:\n",
    "            sleep_time = self.delay - time_since_last_call\n",
    "            time.sleep(sleep_time)\n",
    "        \n",
    "        self.last_call_time = time.time()\n",
    "        self.api_calls += 1\n",
    "        \n",
    "        prompt = f\"\"\"Parse the following course requisite statement and return a JSON object with this exact structure:\n",
    "\n",
    "{{\n",
    "    \"prerequisites\": [\n",
    "        // List of AND-groups, where each group is a list of courses that can be taken as alternatives (OR)\n",
    "        // Example: [[\"COMP 110\"], [\"MATH 231\", \"MATH 241\"]] means COMP 110 AND (MATH 231 OR MATH 241)\n",
    "    ],\n",
    "    \"corequisites\": [\n",
    "        // Same structure as prerequisites but for co-requisites\n",
    "    ],\n",
    "    \"grade_requirements\": {{\n",
    "        // Map of course to required grade\n",
    "        // Example: {{\"COMP 110\": \"C\", \"MATH 231\": \"C+\"}}\n",
    "    }},\n",
    "    \"requisites_note\": // String with any additional requirements like \"permission of instructor\" or null if none\n",
    "}}\n",
    "\n",
    "CRITICAL PARSING RULES:\n",
    "\n",
    "1. AND relationships (all required):\n",
    "   - Separated by \"and\", semicolons (;), or commas in a list\n",
    "   - Example: \"COMP 110 and MATH 231\" → [[\"COMP 110\"], [\"MATH 231\"]]\n",
    "   - Example: \"COMP 210; COMP 211; COMP 301\" → [[\"COMP 210\"], [\"COMP 211\"], [\"COMP 301\"]]\n",
    "\n",
    "2. OR relationships (choose one):\n",
    "   - Separated by \"or\"\n",
    "   - Example: \"COMP 283 or MATH 381 or STOR 315\" → [[\"COMP 283\", \"MATH 381\", \"STOR 315\"]]\n",
    "\n",
    "3. Mixed AND/OR:\n",
    "   - Example: \"MATH 231 or 241; COMP 210, COMP 211, and COMP 301\"\n",
    "   - Parse as: [[\"MATH 231\", \"MATH 241\"], [\"COMP 210\"], [\"COMP 211\"], [\"COMP 301\"]]\n",
    "   - The semicolon separates AND groups, \"or\" creates OR options within a group\n",
    "\n",
    "4. Pre- or corequisites:\n",
    "   - Add the SAME courses to BOTH prerequisites and corequisites arrays\n",
    "   - Example: \"Pre- or corequisites, COMP 283 or MATH 381\"\n",
    "   - Prerequisites: [[\"COMP 283\", \"MATH 381\"]]\n",
    "   - Corequisites: [[\"COMP 283\", \"MATH 381\"]]\n",
    "\n",
    "5. Grade requirements:\n",
    "   - Look for \"grade of X or better\", \"C or better\", etc.\n",
    "   - Apply to ALL courses mentioned in the same clause\n",
    "   - Example: \"COMP 211 and COMP 301; a grade of C or better is required in both\"\n",
    "   - grade_requirements: {{\"COMP 211\": \"C\", \"COMP 301\": \"C\"}}\n",
    "\n",
    "6. Course code format:\n",
    "   - Always format as \"DEPT ###\" with a space (e.g., \"COMP 110\", not \"COMP110\")\n",
    "   - Include letter suffixes if present (e.g., \"BIOL 101L\")\n",
    "\n",
    "7. Special requirements (put in requisites_note):\n",
    "   - \"Permission of the instructor\" → Include exact text\n",
    "   - \"Not open to students who have credit for X\" → Include full restriction\n",
    "   - \"for students lacking the prerequisite\" → Include context\n",
    "   - Any GPA requirements → Include exact GPA needed\n",
    "   - Class standing restrictions (e.g., \"Juniors and seniors only\")\n",
    "\n",
    "Common patterns to recognize:\n",
    "- \"Prerequisites, X and Y\" → both required\n",
    "- \"Prerequisite, X or Y\" → choose one\n",
    "- \"Prerequisites, X; Y or Z\" → X is required AND (Y OR Z)\n",
    "- \"one of the following\" → all listed courses are OR options\n",
    "- \"all of the following\" → all listed courses are AND requirements\n",
    "- \"permission of the instructor for students lacking the prerequisite\" → courses are still required, but add note about permission option\n",
    "\n",
    "Example complex requisite:\n",
    "\"Prerequisites, COMP 211 and 301, or COMP 401, 410, and 411; a grade of C or better is required in all prerequisite courses; permission of the instructor for students lacking the prerequisites/\"\n",
    "\n",
    "Should parse to:\n",
    "{{\n",
    "    \"prerequisites\": [[\"COMP 211\", \"COMP 301\"], [\"COMP 401\", \"COMP 410\", \"COMP 411\"]],\n",
    "    \"corequisites\": [],\n",
    "    \"grade_requirements\": {{\"COMP 211\": \"C\", \"COMP 301\": \"C\", \"COMP 401\": \"C\", \"COMP 410\": \"C\", \"COMP 411\": \"C\"}},\n",
    "    \"requisites_note\": \"permission of the instructor for students lacking the prerequisites\"\n",
    "}}\n",
    "\n",
    "Requisite statement to parse:\n",
    "{raw}\n",
    "\n",
    "Return ONLY the JSON object, no explanation or markdown.\"\"\"\n",
    "\n",
    "        try:\n",
    "            response = self.model.generate_content(prompt)\n",
    "            json_text = response.text.strip()\n",
    "            json_text = re.sub(r'^```json\\s*', '', json_text)\n",
    "            json_text = re.sub(r'\\s*```$', '', json_text)\n",
    "            \n",
    "            result = json.loads(json_text)\n",
    "            return self._validate_result(result)\n",
    "            \n",
    "        except Exception as e:\n",
    "            if course_id:\n",
    "                self.failed_parses.append((course_id, str(e)))\n",
    "            return self._fallback_parse(raw)\n",
    "    \n",
    "    def _validate_result(self, result: dict) -> dict:\n",
    "        \"\"\"Validate and clean the parsed result.\"\"\"\n",
    "        validated = {\n",
    "            \"prerequisites\": result.get(\"prerequisites\", []),\n",
    "            \"corequisites\": result.get(\"corequisites\", []),\n",
    "            \"grade_requirements\": result.get(\"grade_requirements\", {}),\n",
    "            \"requisites_note\": result.get(\"requisites_note\", None)\n",
    "        }\n",
    "        \n",
    "        # Ensure prerequisites and corequisites are lists of lists\n",
    "        for key in [\"prerequisites\", \"corequisites\"]:\n",
    "            if not isinstance(validated[key], list):\n",
    "                validated[key] = []\n",
    "            else:\n",
    "                cleaned_list = []\n",
    "                for item in validated[key]:\n",
    "                    if isinstance(item, list):\n",
    "                        cleaned_list.append(item)\n",
    "                    elif isinstance(item, str):\n",
    "                        cleaned_list.append([item])\n",
    "                validated[key] = cleaned_list\n",
    "        \n",
    "        if not isinstance(validated[\"grade_requirements\"], dict):\n",
    "            validated[\"grade_requirements\"] = {}\n",
    "        \n",
    "        return validated\n",
    "    \n",
    "    def _fallback_parse(self, raw: str) -> dict:\n",
    "        \"\"\"Basic fallback parser if API fails.\"\"\"\n",
    "        course_pattern = re.compile(r'\\b[A-Z]{2,5}\\s?\\d{2,3}[A-Z]?\\d?[A-Z]?\\b')\n",
    "        courses = course_pattern.findall(raw)\n",
    "        \n",
    "        normalized_courses = []\n",
    "        for course in courses:\n",
    "            if ' ' not in course:\n",
    "                course = re.sub(r'([A-Z]+)(\\d)', r'\\1 \\2', course)\n",
    "            normalized_courses.append(course)\n",
    "        \n",
    "        prerequisites = [[course] for course in normalized_courses]\n",
    "        \n",
    "        grade_requirements = {}\n",
    "        if 'C or better' in raw or 'grade of C' in raw:\n",
    "            for course in normalized_courses:\n",
    "                grade_requirements[course.replace(' ', '')] = 'C'\n",
    "        \n",
    "        note = None\n",
    "        if 'permission' in raw.lower() or 'instructor' in raw.lower():\n",
    "            note = \"Permission of instructor may be required\"\n",
    "        \n",
    "        return {\n",
    "            \"prerequisites\": prerequisites,\n",
    "            \"corequisites\": [],\n",
    "            \"grade_requirements\": grade_requirements,\n",
    "            \"requisites_note\": note\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f48d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Scraping functions\n",
    "def get_department_links(only=None):\n",
    "    \"\"\"Scrape all department links from the main courses page.\"\"\"\n",
    "    response = requests.get(COURSE_INDEX_URL)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    index_div = soup.find(\"div\", {\"id\": \"atozindex\"})\n",
    "    links = []\n",
    "\n",
    "    for a in index_div.find_all(\"a\", href=True):\n",
    "        dept_code = a['href'].split(\"/\")[-2].upper()\n",
    "        if only is None or dept_code in only:\n",
    "            links.append((dept_code, urljoin(BASE_URL, a['href'])))\n",
    "\n",
    "    return links\n",
    "\n",
    "def parse_course_block(block, parser: RequisiteParser):\n",
    "    \"\"\"Parse a course block from the HTML.\"\"\"\n",
    "    data = {\n",
    "        \"department\": None,\n",
    "        \"course_number\": None,\n",
    "        \"course_name\": None,\n",
    "        \"credits\": None,\n",
    "        \"description\": None,\n",
    "        \"requisites\": {\"prerequisites\": [], \"corequisites\": []},\n",
    "        \"grade_requirements\": {},\n",
    "        \"requisites_note\": None,\n",
    "        \"gen_ed\": None,\n",
    "        \"grading_status\": None,\n",
    "        \"repeat_rules\": None\n",
    "    }\n",
    "\n",
    "    # Header line\n",
    "    header = block.find(\"div\", class_=\"cols noindent\")\n",
    "    if header:\n",
    "        strong_tags = header.find_all(\"strong\")\n",
    "        if len(strong_tags) >= 3:\n",
    "            code = strong_tags[0].text.strip()\n",
    "            if \" \" in code:\n",
    "                data[\"department\"], data[\"course_number\"] = code.split(\" \", 1)\n",
    "                data[\"course_number\"] = data[\"course_number\"].rstrip(\".\")\n",
    "            data[\"course_id\"] = f\"{data['department']} {data['course_number']}\"\n",
    "            data[\"course_name\"] = strong_tags[1].text.strip()\n",
    "            data[\"credits\"] = strong_tags[2].text.strip().replace(\" Credits.\", \"\")\n",
    "\n",
    "    # Description\n",
    "    desc_block = block.find(\"p\", class_=\"courseblockextra\")\n",
    "    if desc_block:\n",
    "        data[\"description\"] = desc_block.text.strip()\n",
    "\n",
    "    # Requisites\n",
    "    req_span = block.find(\"span\", class_=\"text detail-requisites margin--default\")\n",
    "    if req_span:\n",
    "        course_id = data.get(\"course_id\", \"Unknown\")\n",
    "        req_data = parser.parse_requisites(req_span.text, course_id)\n",
    "        data[\"requisites\"] = {\n",
    "            \"prerequisites\": req_data[\"prerequisites\"],\n",
    "            \"corequisites\": req_data[\"corequisites\"]\n",
    "        }\n",
    "        data[\"grade_requirements\"] = req_data[\"grade_requirements\"]\n",
    "        data[\"requisites_note\"] = req_data[\"requisites_note\"]\n",
    "\n",
    "    # Repeat Rules\n",
    "    repeat_span = block.find(\"span\", class_=\"text detail-repeat_rules margin--default\")\n",
    "    if repeat_span:\n",
    "        repeat_text = repeat_span.text.strip()\n",
    "        # Remove the \"Repeat Rules:\" prefix if present\n",
    "        if repeat_text.startswith(\"Repeat Rules:\"):\n",
    "            repeat_text = repeat_text.replace(\"Repeat Rules:\", \"\").strip()\n",
    "        \n",
    "        # Parse the repeat rules\n",
    "        repeat_data = parse_repeat_rules(repeat_text)\n",
    "        if repeat_data:\n",
    "            data[\"repeat_rules\"] = repeat_data\n",
    "\n",
    "    # Gen Ed - parse structured format\n",
    "    idea_span = block.find(\"span\", class_=\"text detail-idea_action margin--default\")\n",
    "    if idea_span:\n",
    "        gen_ed_text = idea_span.text.strip().replace(\"IDEAs in Action Gen Ed:\", \"\").strip()\n",
    "        data[\"gen_ed\"] = parse_gen_ed_requirements(gen_ed_text)\n",
    "\n",
    "    # Grading\n",
    "    grading_span = block.find(\"span\", class_=\"text detail-grading_status margin--default\")\n",
    "    if grading_span:\n",
    "        data[\"grading_status\"] = grading_span.text.strip().replace(\"Grading Status: \", \"\")\n",
    "\n",
    "    return data\n",
    "\n",
    "def parse_repeat_rules(repeat_text: str):\n",
    "    \"\"\"\n",
    "    Parse repeat rules to extract structured information.\n",
    "    \n",
    "    Example input: \"May be repeated for credit. 9 total credits. 3 total completions.\"\n",
    "    \n",
    "    Returns:\n",
    "    {\n",
    "        \"repeatable\": True,\n",
    "        \"max_credits\": 9,\n",
    "        \"max_completions\": 3,\n",
    "        \"raw_text\": \"May be repeated for credit. 9 total credits. 3 total completions.\"\n",
    "    }\n",
    "    \"\"\"\n",
    "    if not repeat_text:\n",
    "        return None\n",
    "    \n",
    "    import re\n",
    "    \n",
    "    result = {\n",
    "        \"repeatable\": False,\n",
    "        \"max_credits\": None,\n",
    "        \"max_completions\": None,\n",
    "        \"raw_text\": repeat_text\n",
    "    }\n",
    "    \n",
    "    # Check if course is repeatable\n",
    "    if \"may be repeated\" in repeat_text.lower() or \"can be repeated\" in repeat_text.lower():\n",
    "        result[\"repeatable\"] = True\n",
    "    \n",
    "    # Extract total credits\n",
    "    credits_match = re.search(r'(\\d+)\\s*total\\s*credits?', repeat_text, re.IGNORECASE)\n",
    "    if credits_match:\n",
    "        result[\"max_credits\"] = int(credits_match.group(1))\n",
    "    \n",
    "    # Extract total completions\n",
    "    completions_match = re.search(r'(\\d+)\\s*total\\s*completions?', repeat_text, re.IGNORECASE)\n",
    "    if completions_match:\n",
    "        result[\"max_completions\"] = int(completions_match.group(1))\n",
    "    \n",
    "    return result\n",
    "\n",
    "def parse_gen_ed_requirements(gen_ed_text: str):\n",
    "    \"\"\"\n",
    "    Parse gen ed requirements with AND/OR logic.\n",
    "    \n",
    "    Examples:\n",
    "    - \"FY-SEMINAR, FC-PAST or FC-POWER\" -> [[\"FY-SEMINAR\"], [\"FC-PAST\", \"FC-POWER\"]]\n",
    "    - \"FY-SEMINAR\" -> [[\"FY-SEMINAR\"]]\n",
    "    - \"FC-PAST or FC-POWER\" -> [[\"FC-PAST\", \"FC-POWER\"]]\n",
    "    \n",
    "    Returns a list of lists where:\n",
    "    - Outer list items are AND'ed (all required)\n",
    "    - Inner list items are OR'ed (choose one)\n",
    "    \"\"\"\n",
    "    if not gen_ed_text:\n",
    "        return []\n",
    "    \n",
    "    # Split by commas for AND groups\n",
    "    and_groups = [group.strip() for group in gen_ed_text.split(',')]\n",
    "    \n",
    "    result = []\n",
    "    for group in and_groups:\n",
    "        # Check if this group has OR options\n",
    "        if ' or ' in group.lower():\n",
    "            # Split by 'or' for OR options\n",
    "            or_options = [opt.strip() for opt in re.split(r'\\s+or\\s+', group, flags=re.IGNORECASE)]\n",
    "            result.append(or_options)\n",
    "        else:\n",
    "            # Single requirement\n",
    "            result.append([group])\n",
    "    \n",
    "    return result\n",
    "\n",
    "def parse_department(url, parser: RequisiteParser, dept_code: str, db_manager: DatabaseManager, mode: str = 'database'):\n",
    "    \"\"\"Parse all courses from a department page.\"\"\"\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    course_blocks = soup.find_all(\"div\", class_=\"courseblock\")\n",
    "    \n",
    "    total_courses = len(course_blocks)\n",
    "    print(f\"   Found {total_courses} courses to parse\")\n",
    "    \n",
    "    courses = []\n",
    "    saved_count = 0\n",
    "    \n",
    "    for i, cb in enumerate(course_blocks, 1):\n",
    "        # Extract course ID for progress display\n",
    "        header = cb.find(\"div\", class_=\"cols noindent\")\n",
    "        course_id = \"Unknown\"\n",
    "        if header:\n",
    "            strong_tags = header.find_all(\"strong\")\n",
    "            if strong_tags:\n",
    "                course_id = strong_tags[0].text.strip()\n",
    "        \n",
    "        print(f\"   Processing {course_id} ({i}/{total_courses})...\", end='\\r')\n",
    "        \n",
    "        course_data = parse_course_block(cb, parser)\n",
    "        \n",
    "        # Save to database if in database mode\n",
    "        if mode in ['database', 'both'] and db_manager:\n",
    "            try:\n",
    "                db_manager.save_course(course_data)\n",
    "                saved_count += 1\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Failed to save {course_id}: {e}\")\n",
    "        \n",
    "        # Collect for JSON if needed\n",
    "        if mode in ['json', 'both']:\n",
    "            courses.append(course_data)\n",
    "    \n",
    "    print(f\"   ✓ Completed all {total_courses} courses in {dept_code} (saved {saved_count} to database)     \")\n",
    "    return courses\n",
    "\n",
    "def scrape_all_courses(parser: RequisiteParser, db_manager: Optional[DatabaseManager] = None, \n",
    "                      only=None, mode='database', dry_run=False, update_existing=True):\n",
    "    \"\"\"\n",
    "    Scrape all courses with flexible output options.\n",
    "    \n",
    "    Args:\n",
    "        parser: RequisiteParser instance\n",
    "        db_manager: DatabaseManager instance (required for database mode)\n",
    "        only: Set of department codes to scrape (None for all)\n",
    "        mode: 'database', 'json', or 'both'\n",
    "        dry_run: If True, don't actually save anything\n",
    "        update_existing: If True, update existing courses; if False, skip them\n",
    "    \"\"\"\n",
    "    department_links = get_department_links(only=only)\n",
    "    all_courses = {}\n",
    "    \n",
    "    print(f\"\\n🎯 Starting scrape of {len(department_links)} departments\")\n",
    "    print(f\"   Mode: {mode}\")\n",
    "    print(f\"   Dry run: {dry_run}\")\n",
    "    print(f\"   Update existing: {update_existing}\\n\")\n",
    "    \n",
    "    overall_start_time = time.time()\n",
    "\n",
    "    for dept_idx, (dept_code, url) in enumerate(department_links, 1):\n",
    "        try:\n",
    "            print(f\"📚 [{dept_idx}/{len(department_links)}] Scraping {dept_code}...\")\n",
    "            dept_start_time = time.time()\n",
    "            \n",
    "            # Begin transaction for this department\n",
    "            if db_manager and not dry_run:\n",
    "                db_manager.conn.commit()  # Commit any pending changes\n",
    "            \n",
    "            courses = parse_department(url, parser, dept_code, db_manager if not dry_run else None, mode)\n",
    "            \n",
    "            if mode in ['json', 'both']:\n",
    "                all_courses[dept_code] = courses\n",
    "            \n",
    "            # Commit department transaction\n",
    "            if db_manager and not dry_run and mode in ['database', 'both']:\n",
    "                db_manager.commit()\n",
    "            \n",
    "            dept_elapsed = time.time() - dept_start_time\n",
    "            print(f\"✅ Successfully scraped {dept_code} in {dept_elapsed/60:.1f} minutes\\n\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error scraping {dept_code}: {e}\\n\")\n",
    "            if db_manager and not dry_run:\n",
    "                db_manager.rollback()\n",
    "    \n",
    "    overall_elapsed = time.time() - overall_start_time\n",
    "    print(f\"⏱️  Total scraping time: {overall_elapsed/60:.1f} minutes\")\n",
    "    \n",
    "    return all_courses\n",
    "\n",
    "def save_to_json(data, filename=\"unc_courses.json\"):\n",
    "    \"\"\"Save course data to JSON file.\"\"\"\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, indent=2, ensure_ascii=False)\n",
    "    print(f\"\\n💾 Saved to {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9fb77b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-22 21:44:56,588 - INFO - Loaded 152 departments and 10212 courses into cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🎯 Starting scrape of 2 departments\n",
      "   Mode: json\n",
      "   Dry run: True\n",
      "   Update existing: True\n",
      "\n",
      "📚 [1/2] Scraping ENGL...\n",
      "   Found 341 courses to parse\n",
      "   ✓ Completed all 341 courses in ENGL (saved 0 to database)     \n",
      "✅ Successfully scraped ENGL in 1.0 minutes\n",
      "\n",
      "📚 [2/2] Scraping HIST...\n",
      "   Found 416 courses to parse\n",
      "   ✓ Completed all 416 courses in HIST (saved 0 to database)     \n",
      "✅ Successfully scraped HIST in 0.1 minutes\n",
      "\n",
      "⏱️  Total scraping time: 1.0 minutes\n",
      "\n",
      "💾 Saved to unc_courses_sample.json\n",
      "\n",
      "📊 Statistics:\n",
      "   Total API calls: 30\n",
      "   Failed parses: 0\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Main execution\n",
    "# Initialize components\n",
    "parser = RequisiteParser(model=\"gemini-1.5-flash\", delay=2.1)\n",
    "db_manager = DatabaseManager(DATABASE_URL)\n",
    "\n",
    "# Configuration options\n",
    "MODE = 'database'  # 'database', 'json', or 'both'\n",
    "DRY_RUN = False    # Set to True to test without saving\n",
    "UPDATE_EXISTING = True  # Set to False to skip existing courses\n",
    "\n",
    "# Option 1: Scrape sample departments\n",
    "sample_departments = {\"COMP\", \"BIOL\", \"CHEM\"}\n",
    "courses = scrape_all_courses(\n",
    "    parser, \n",
    "    db_manager,\n",
    "    only=sample_departments,\n",
    "    mode=MODE,\n",
    "    dry_run=DRY_RUN,\n",
    "    update_existing=UPDATE_EXISTING\n",
    ")\n",
    "\n",
    "# Save JSON backup if requested\n",
    "if MODE in ['json', 'both'] and courses:\n",
    "    save_to_json(courses, \"unc_courses_sample.json\")\n",
    "\n",
    "# Option 2: Scrape all departments (uncomment to use)\n",
    "# courses = scrape_all_courses(parser, db_manager, mode=MODE)\n",
    "# if MODE in ['json', 'both'] and courses:\n",
    "#     save_to_json(courses, \"unc_courses_all.json\")\n",
    "\n",
    "# Print statistics\n",
    "print(f\"\\n📊 Statistics:\")\n",
    "print(f\"   Total API calls: {parser.api_calls}\")\n",
    "print(f\"   Failed parses: {len(parser.failed_parses)}\")\n",
    "if parser.failed_parses:\n",
    "    print(\"\\n⚠️  Failed to parse requisites for:\")\n",
    "    for course_id, error in parser.failed_parses[:5]:\n",
    "        print(f\"   - {course_id}: {error[:50]}...\")\n",
    "    if len(parser.failed_parses) > 5:\n",
    "        print(f\"   ... and {len(parser.failed_parses) - 5} more\")\n",
    "\n",
    "# Close database connection\n",
    "db_manager.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28faaee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Database Contents:\n",
      "   Total courses: 10212\n",
      "   Courses with prerequisites: 2405\n",
      "\n",
      "📚 Sample courses:\n",
      "   COMP 110: Introduction to Programming.\n",
      "   COMP 211: Systems Fundamentals.\n",
      "      Prerequisites: 1 groups\n",
      "   BIOL 101: Principles of Biology.\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Database verification\n",
    "def verify_scraping_results():\n",
    "    \"\"\"Verify what was scraped into the database.\"\"\"\n",
    "    from db_queries import CourseDatabase\n",
    "    \n",
    "    with CourseDatabase() as db:\n",
    "        stats = db.get_database_stats()\n",
    "        print(\"\\n🔍 Database Contents:\")\n",
    "        print(f\"   Total courses: {stats['total_courses']}\")\n",
    "        print(f\"   Courses with prerequisites: {stats['courses_with_prereqs']}\")\n",
    "        \n",
    "        # Show sample courses\n",
    "        print(\"\\n📚 Sample courses:\")\n",
    "        sample_courses = [\"COMP 110\", \"COMP 211\", \"BIOL 101\"]\n",
    "        for course_id in sample_courses:\n",
    "            course = db.get_course(course_id)\n",
    "            if course:\n",
    "                prereqs = db.get_course_prerequisites(course_id)\n",
    "                print(f\"   {course_id}: {course['name']}\")\n",
    "                if prereqs['prerequisites']:\n",
    "                    print(f\"      Prerequisites: {len(prereqs['prerequisites'])} groups\")\n",
    "\n",
    "# Run verification\n",
    "verify_scraping_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e465a4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Analyzing 152 departments...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning departments: 100%|██████████| 152/152 [01:12<00:00,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Requisite Analysis Complete!\n",
      "\n",
      "Total courses across all departments: 10212\n",
      "Courses with requisites: 2759\n",
      "Courses without requisites: 7453\n",
      "Percentage with requisites: 27.0%\n",
      "\n",
      "💡 You will need 2759 API calls\n",
      "⏱️  Estimated time at 2.1s/call: 96.6 minutes\n",
      "\n",
      "📈 Top 10 departments by requisite count:\n",
      "   BIOL: 167/264 courses (63%)\n",
      "   PSYC: 101/183 courses (55%)\n",
      "   NURS: 91/169 courses (54%)\n",
      "   ECON: 81/145 courses (56%)\n",
      "   COMP: 79/109 courses (72%)\n",
      "   PHCY: 75/112 courses (67%)\n",
      "   CHEM: 74/112 courses (66%)\n",
      "   SPAN: 71/119 courses (60%)\n",
      "   MATH: 70/110 courses (64%)\n",
      "   COMM: 69/213 courses (32%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell to count non-empty requisites across all departments\n",
    "def count_requisites(only=None):\n",
    "    \"\"\"Count how many courses have non-empty requisites across departments.\"\"\"\n",
    "    department_links = get_department_links(only=only)\n",
    "    \n",
    "    total_courses = 0\n",
    "    courses_with_requisites = 0\n",
    "    dept_stats = {}\n",
    "    \n",
    "    print(f\"🔍 Analyzing {len(department_links)} departments...\\n\")\n",
    "    \n",
    "    for dept_code, url in tqdm(department_links, desc=\"Scanning departments\"):\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        course_blocks = soup.find_all(\"div\", class_=\"courseblock\")\n",
    "        \n",
    "        dept_total = len(course_blocks)\n",
    "        dept_with_reqs = 0\n",
    "        \n",
    "        for block in course_blocks:\n",
    "            req_span = block.find(\"span\", class_=\"text detail-requisites margin--default\")\n",
    "            if req_span and req_span.text.strip() and req_span.text.strip() != \"Requisites:\":\n",
    "                dept_with_reqs += 1\n",
    "        \n",
    "        dept_stats[dept_code] = {\n",
    "            \"total\": dept_total,\n",
    "            \"with_requisites\": dept_with_reqs,\n",
    "            \"percentage\": (dept_with_reqs / dept_total * 100) if dept_total > 0 else 0\n",
    "        }\n",
    "        \n",
    "        total_courses += dept_total\n",
    "        courses_with_requisites += dept_with_reqs\n",
    "    \n",
    "    # Print summary\n",
    "    print(f\"\\n📊 Requisite Analysis Complete!\\n\")\n",
    "    print(f\"Total courses across all departments: {total_courses}\")\n",
    "    print(f\"Courses with requisites: {courses_with_requisites}\")\n",
    "    print(f\"Courses without requisites: {total_courses - courses_with_requisites}\")\n",
    "    print(f\"Percentage with requisites: {courses_with_requisites/total_courses*100:.1f}%\")\n",
    "    print(f\"\\n💡 You will need {courses_with_requisites} API calls\")\n",
    "    print(f\"⏱️  Estimated time at 2.1s/call: {courses_with_requisites * 2.1 / 60:.1f} minutes\")\n",
    "    \n",
    "    # Show top departments by requisite count\n",
    "    print(f\"\\n📈 Top 10 departments by requisite count:\")\n",
    "    sorted_depts = sorted(dept_stats.items(), key=lambda x: x[1]['with_requisites'], reverse=True)[:10]\n",
    "    for dept, stats in sorted_depts:\n",
    "        print(f\"   {dept}: {stats['with_requisites']}/{stats['total']} courses ({stats['percentage']:.0f}%)\")\n",
    "    \n",
    "    return dept_stats\n",
    "\n",
    "# Run the analysis\n",
    "# For all departments:\n",
    "dept_stats = count_requisites()\n",
    "\n",
    "# Or for specific departments:\n",
    "# dept_stats = count_requisites(only={\"COMP\", \"MATH\", \"BIOL\", \"CHEM\", \"PHYS\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pathfinder",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
